[{"categories":null,"contents":" Bohr–Van Leeuwen theorem The Bohr–Van Leeuwen theorem states that when statistical mechanics and classical mechanics are applied consistently, the thermal average of the magnetization is always zero. This makes magnetism in solids solely a quantum mechanical effect and means that classical physics cannot account for paramagnetism, diamagnetism and ferromagnetism. Groenewold-van Hove theorem Groenewold\u0026rsquo;s theorem, also known as the Groenewold-van Hove theorem, is a fundamental result in the theory of quantization, which demonstrates the impossibility of a consistent mapping from classical observables to quantum operators that preserves the Poisson bracket structure.\nIt shows that it is impossible to consistently quantize all classical observables while maintaining the correspondence between Poisson brackets and quantum commutators. The theorem has significant implications for the foundations of quantum mechanics, as it highlights the limitations of canonical quantization and the challenges of formulating a consistent quantum theory from classical mechanics.\nGroenewold\u0026rsquo;s theorem also has connections to the Wigner-Weyl transform, which provides a way to map between phase-space functions and quantum operators. However, Groenewold\u0026rsquo;s theorem asserts that no such map can have all the ideal properties one would desire for a consistent quantization scheme. Despite this, the Wigner-Weyl transform remains a valuable tool for understanding quantum mechanics in phase space.\ngroenewold van hove theorem\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://oameye.github.io/notes/physics/facts/","summary":"\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eBohr–Van Leeuwen theorem\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003eThe \u003cstrong\u003eBohr–Van Leeuwen theorem\u003c/strong\u003e states that when statistical mechanics and classical mechanics are applied consistently, the thermal average of the magnetization is always zero. This makes \u003cem\u003emagnetism\u003c/em\u003e in solids solely a \u003cem\u003equantum mechanical effect\u003c/em\u003e and means that classical physics cannot account for paramagnetism, diamagnetism and ferromagnetism.\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e\n\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eGroenewold-van Hove theorem\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cp\u003eGroenewold\u0026rsquo;s theorem, also known as the \u003cstrong\u003eGroenewold-van Hove theorem\u003c/strong\u003e, is a fundamental result in the theory of quantization, which demonstrates the impossibility of a consistent mapping from classical observables to quantum operators that preserves the Poisson bracket structure.\u003c/p\u003e","tags":null,"title":"Facts"},{"categories":null,"contents":" Optimal Control and Physics Cool Things in Optimal Control and Physics ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://oameye.github.io/notes/physics/optimal-control/","summary":"\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eOptimal Control and Physics\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003ca href=\"https://cgliu.github.io/posts/optimal-control/optimization-physics.html\" target=\"_blank\" rel=\"noopener\"\u003e\u003cstrong\u003eCool Things in Optimal Control and Physics\u003c/strong\u003e\u003c/a\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e","tags":null,"title":"Optimal Control"},{"categories":null,"contents":" Resource aggregators PhD Resources of Guillaume Dalle: Collection of cool resources, websites and software to improve your workflow and make your life easier! Awesome PhD by Helena Hartmann: A curated list of carefully selected tools and resources I wish I knew when starting my PhD. Survival of the Firstest https://peterse.github.io/2024/04/02/Survival-of-the-firstest.html?s=09 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://oameye.github.io/notes/academic_life/resources/","summary":"\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eResource aggregators\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://phd-resources.github.io/\" target=\"_blank\" rel=\"noopener\"\u003e\u003cstrong\u003ePhD Resources\u003c/strong\u003e\u003c/a\u003e of Guillaume Dalle: Collection of cool resources, websites and software to improve your workflow and make your life easier!\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://phd-resources.github.io/\" target=\"_blank\" rel=\"noopener\"\u003e\u003cstrong\u003eAwesome PhD\u003c/strong\u003e\u003c/a\u003e by Helena Hartmann: A curated list of carefully selected tools and resources I wish I knew when starting my PhD.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e\n\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eSurvival of the Firstest\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003ca href=\"https://peterse.github.io/2024/04/02/Survival-of-the-firstest.html?s=09\" target=\"_blank\" rel=\"noopener\"\u003ehttps://peterse.github.io/2024/04/02/Survival-of-the-firstest.html?s=09\u003c/a\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e","tags":null,"title":"Resources"},{"categories":null,"contents":"My OS \u0026amp; Software Stack Operating System Aurora (Universal Blue) - An immutable Linux distribution based on Fedora Silverblue with KDE Plasma desktop. Provides atomic updates and a reliable, modern desktop experience.\nDesktop Environment: KDE Plasma with Sweet theme for a clean, dark interface.\nDevelopment Environment Editors \u0026amp; IDEs VS Code - Primary code editor with excellent Julia and Python support Jupyter Lab - Interactive computing environment for data analysis and prototyping Terminal Konsole - KDE\u0026rsquo;s terminal emulator Yakuake - Drop-down terminal for quick access Bash - Reliable shell for daily tasks Programming Languages Julia - Primary language for scientific computing and numerical analysis Python - Secondary language for broader ecosystem access Mathematica/Wolfram Language - Symbolic computation and mathematical analysis Typst - Modern markup language for typesetting and document preparation Key Libraries \u0026amp; Packages SciML ecosystem (Julia) - Scientific machine learning and differential equations Makie (Julia) - High-performance data visualization HarmonicBalance.jl (Julia) - Harmonic balance method for nonlinear dynamics Sneg (Mathematica) - Symbolic calculation for quantum many-body systems Development Tools Version Control \u0026amp; Containers Git - Version control and repository management Distrobox - Containerization for isolated development environments Productivity \u0026amp; Research Zotero - Reference management for academic papers Notion - Project organization and structured notes Obsidian - Knowledge management and interconnected notes Nextcloud - Self-hosted cloud storage and file synchronization Graphics \u0026amp; Design Inkscape - Vector graphics creation and scientific diagrams GIMP - Raster image editing and figure preparation Web Browser Brave - Privacy-focused browser with built-in ad blocking Communication Element - Matrix-based secure messaging Mattermost - Team collaboration platform Zulip - Organized team chat with threading Slack - General workplace communication ","date":"July 19, 2025","hero":"/posts/setup/preview.png","permalink":"https://oameye.github.io/posts/setup/","summary":"An overview of my OS and software stack for scientific computing.","tags":["setup","tools","scientific-computing"],"title":"My Setup"},{"categories":null,"contents":"A summary of my recent open source contributions, including merged pull requests.\nNote: This document is automatically generated using the GitHub CLI and updated regularly to reflect the latest contributions.\nGenerated on July 19, 2025\n🔥 Recent Merged Contributions (External Repositories) QuantumEngineeredSystems/HarmonicSteadyState.jl - fix: swept_parameter with BasicSymbolic (merged 2025-07-19) QuantumEngineeredSystems/HarmonicSteadyState.jl - fix: streamline sorting options (merged 2025-07-19) QuantumEngineeredSystems/HarmonicBalance.jl - docs: add forward transmission example and update documentation API (merged 2025-07-19) QuantumEngineeredSystems/HarmonicBalance.jl - build: bump HarmonicSteadyState compat (merged 2025-07-19) qutip/qutip-julia-tutorials - implement suggestions to QFI tutorial (merged 2025-07-14) QuantumEngineeredSystems/HarmonicSteadyState.jl - build: tag patch release (merged 2025-07-10) QuantumEngineeredSystems/HarmonicSteadyState.jl - export get_branches (merged 2025-07-10) QuantumEngineeredSystems/HarmonicSteadyState.jl - build: tag patch version (merged 2025-07-08) QuantumEngineeredSystems/HarmonicSteadyState.jl - feat: add get_branches (merged 2025-07-08) QuantumEngineeredSystems/HarmonicSteadyState.jl - fix: hopf definition (merged 2025-07-07) 🚀 My Open Source Projects Julia Packages KeldyshContraction.jl ⭐ 8 Perform wick contraction on a Keldysh contour Created: 2025-04-17 PIMC.jl ⭐ 7 ab-initio continuous path integral Monte Carlo Created: 2022-07-09 VanVleckRecursion.jl ⭐ 3 Symbolic calculation of the (van Vleck) Floquet recursion formula Created: 2025-06-01 GraphCombinations.jl ⭐ 3 Generate all combinations of graphs and their symmetry factor Created: 2025-04-30 SingleParticleLocalisation.jl ⭐ 2 Created: 2022-03-15 FloquetExpansions.jl ⭐ 1 Created: 2025-06-08 OhMyFFT.jl ⭐ 1 An opinionated layer on top of FFTW.jl. Fork of EasyFFTs.jl Created: 2024-11-20 Sgmam.jl ⭐ 1 Created: 2024-08-08 Tools \u0026amp; Utilities zotero_engines ⭐ 1 zotero engines.json Created: 2024-10-01 Personal Projects oameye.github.io ⭐ 1 Created: 2022-03-15 📝 All Merged Pull Requests by Organization (External Repositories) QuantumEngineeredSystems (254 PRs) As main maintainer of QuantumEngineeredSystems packages:\n254 merged PRs Active development across 3 repositories: HarmonicBalance.jl: 192 PRs HarmonicSteadyState.jl: 33 PRs QuestBase.jl: 29 PRs Recent contributions (last 5):\nQuantumEngineeredSystems/HarmonicSteadyState.jl - fix: swept_parameter with BasicSymbolic (merged 2025-07-19) QuantumEngineeredSystems/HarmonicSteadyState.jl - fix: streamline sorting options (merged 2025-07-19) QuantumEngineeredSystems/HarmonicBalance.jl - docs: add forward transmission example and update documentation API (merged 2025-07-19) QuantumEngineeredSystems/HarmonicBalance.jl - build: bump HarmonicSteadyState compat (merged 2025-07-19) QuantumEngineeredSystems/HarmonicSteadyState.jl - build: tag patch release (merged 2025-07-10) JuliaDynamics (61 PRs) CriticalTransitions.jl (55 PRs) - Co-creator and main contributor\nRecent CriticalTransitions.jl contributions (last 3):\nJuliaDynamics/CriticalTransitions.jl - Revert \u0026ldquo;docs: add logo and update flowchart (#171)\u0026rdquo; (merged 2025-06-21) JuliaDynamics/CriticalTransitions.jl - chore: update copyright years in LICENSE file (merged 2025-06-21) JuliaDynamics/CriticalTransitions.jl - docs: sync example folder with docs using Literate (merged 2025-06-21) Other JuliaDynamics contributions:\nJuliaDynamics/DynamicalSystemsBase.jl - add CoupledSDEs(ds::CoupledSDEs, diffeq) method (merged 2024-12-26) JuliaDynamics/DynamicalSystemsBase.jl - fix: set max time span to 1e16 for CoupledSDEs (merged 2024-12-01) JuliaDynamics/DynamicalSystemsBase.jl - feat: MTK Jacobian for CoupledDEs (merged 2024-11-23) JuliaDynamics/DynamicalSystemsBase.jl - let diffusion_matrix(::CoupledSDEs) export a matrix (merged 2024-10-04) JuliaDynamics/DynamicalSystemsBase.jl - add coupledSDEs type (merged 2024-07-24) JuliaDynamics/DrWatson.jl - Update real_world.md (merged 2022-11-17) qojulia (36 PRs) SecondQuantizedAlgebra.jl (25 PRs) - Major contributor and maintainer\nRecent SecondQuantizedAlgebra.jl contributions (last 3):\nqojulia/SecondQuantizedAlgebra.jl - build: bump patch version (merged 2025-07-02) qojulia/SecondQuantizedAlgebra.jl - fix: update unnecessary ModelingToolkit strict compat (merged 2025-07-02) qojulia/SecondQuantizedAlgebra.jl - feat: remove MTK (merged 2025-06-29) Other qojulia contributions:\nqojulia/QuantumCumulants.jl - build: bump compat to SymbolicUtils \u0026gt; v3.26 (merged 2025-06-23) qojulia/QuantumCumulants.jl - refactor: make import and export explicit (merged 2025-06-22) qojulia/QuantumCumulants.jl - test: add potential code quality tests (merged 2025-06-21) qojulia/QuantumCumulants.jl - build: update Documenter workflow (merged 2025-06-21) qojulia/QuantumCumulants.jl - build: add spelling checker (merged 2025-06-21) qojulia/QuantumCumulants.jl - build: update Tests workflow (merged 2025-06-21) qojulia/QuantumCumulants.jl - fix: unsupported SymbolicUtils.SmallVector (merged 2025-06-06) qojulia/QuantumCumulants.jl - seperate quantum algebra from cumulant expansion (merged 2025-05-10) qojulia/QuantumCumulants.jl - remove adjoint method (merged 2024-09-05) qojulia/QuantumCumulants.jl - modify compatibility for SymbolicUtils (merged 2024-07-18) qojulia/QuantumCumulants.jl - add SymbolicsUtils.expand function for QAdd (merged 2024-05-05) SciML (7 PRs) SciML/ModelingToolkit.jl - fix: add Complex to check floating point sym (merged 2025-06-29) SciML/ModelingToolkit.jl - fix: spelling typos (merged 2025-06-24) SciML/ModelingToolkit.jl - fix: enable support for complex ODEProblem again (merged 2025-06-24) SciML/StochasticDiffEq.jl - build: replace OrdinaryDiffEq with OrdinaryDiffEqCore (merged 2025-01-22) SciML/SciMLBase.jl - add additative noise trait (merged 2024-08-29) SciML/SciMLBase.jl - add g kwarg to remake(::SDEProblem) (merged 2024-07-21) SciML/DiffEqNoiseProcess.jl - add covariance field to NoiseProcess struct (merged 2024-07-16) qutip (2 PRs) qutip/qutip-julia-tutorials - implement suggestions to QFI tutorial (merged 2025-07-14) qutip/qutip-julia-tutorials - add QFI example (merged 2025-06-13) control-toolbox (2 PRs) control-toolbox/OptimalControl.jl - fix: typo in mam tutorial (merged 2025-04-24) control-toolbox/OptimalControl.jl - docs: add oc_mam (merged 2025-01-15) Homebrew (1 PRs) Homebrew/homebrew-core - dvisvgm 3.5 (new formula) (merged 2025-06-06) JuliaRegistries (1 PRs) JuliaRegistries/General - change url HarmonicBalance due to organization name change (merged 2025-03-19) JuliaLLVM (1 PRs) JuliaLLVM/LLVM.jl - Update README.md (merged 2025-01-11) JuliaHomotopyContinuation (1 PRs) JuliaHomotopyContinuation/HomotopyContinuation.jl - fix: fix total degree with many parameters threaded (#599) (merged 2024-11-03) LuxDL (1 PRs) LuxDL/DocumenterVitepress.jl - Fix typo in docs (merged 2024-08-12) JuliaSymbolics (1 PRs) JuliaSymbolics/SymbolicUtils.jl - fix typo of docs rule (merged 2024-08-02) julia-actions (1 PRs) julia-actions/julia-format - set julia-cache action to v2 (merged 2024-06-12) JuliaDocs (1 PRs) JuliaDocs/Documenter.jl - update to setup-julia@v2 in the Github action example (merged 2024-04-18) bifurcationkit (1 PRs) bifurcationkit/BifurcationKitDocs.jl - Update gettingstarted.md (merged 2023-10-21) rokzitko (1 PRs) rokzitko/sneg - add installation section (merged 2023-03-05) quarto-dev (1 PRs) quarto-dev/quarto-web - Correcting error in website-basics.qmd (merged 2022-10-08) This document was automatically generated using the GitHub CLI.\n","date":"July 14, 2025","hero":"/posts/open_source_contributions/preview.svg","permalink":"https://oameye.github.io/posts/open_source_contributions/","summary":"A summary of my recent open source contributions, including merged pull requests.","tags":null,"title":"Open Source Contributions"},{"categories":null,"contents":"%matplotlib inline from numpy import * import matplotlib.pyplot as plt from qutip import * Introduction In Bose et al. PRA 56, 4175 (1997), the authors consider the preparation of nonclassical states in cavities with moving mirror. The nonclassical states are achived by letting the system evolve for a specific duration of time. Here we reproduce some of the results of Bose et al.using numberical simulations of the Schrodinger and master equations using QuTiP.\nHamiltonian and initial state The Hamiltonian of the cavity with a moving mirror is\n$H = \\hbar\\omega_0 a^\\dagger a + \\hbar\\omega_m b^\\dagger b - \\hbar g a^\\dagger a (b + b^\\dagger)$\nwhere $\\omega_0$ is the cavity frequency, $\\omega_m$ is the frequency of the oscillation mode of the mirror and $g$ is the opto-mechanical coupling strength. The creation operators of the cavity mode and the mirror mode are $a$ and $b$, respectively.\nThe initial states of the cavity mode and the mirror mode are in the coherent states $|\\alpha\\rangle$ and $|\\beta\\rangle$, respectively.\nUndamped dynamics # number of fock states in the cavity and mirror modes N = 15 M = 30 r = 1.0 def solve_dynamics_undamped(r, k, alpha, beta, t, N, M): wm = 1 w0 = r * wm g = k * wm a = tensor(destroy(N), identity(M)) b = tensor(identity(N), destroy(M)) H = w0 * a.dag() * a + wm * b.dag() * b - g * a.dag() * a * (b + b.dag()) psi0 = tensor(coherent(N, alpha), coherent(M, beta)) options = {\u0026#34;nsteps\u0026#34;: 15_000} result = mesolve(H, psi0, t, options=options) return result, expect(commutator(a, a.dag()), result.states), expect(commutator(b, b.dag()), result.states) #return result, expect(a.dag() * a, result.states), expect(b.dag() * b, result.states) Figure 1 in Bose et al. t = linspace(0, 2 * pi, 50) alpha = beta = 2 result, C1_A, C1_B = solve_dynamics_undamped(r, 0.1, alpha, beta, t, N, M) S1 = [entropy_linear(ptrace(rho, 1)) for rho in result.states] result, C2_A, C2_B = solve_dynamics_undamped(r, 0.5, alpha, beta, t, N, 2*M) S2 = [entropy_linear(ptrace(rho, 1)) for rho in result.states] result, C3_A, C3_B = solve_dynamics_undamped(r, 1.0, alpha, beta, t, N, 10*M) S3 = [entropy_linear(ptrace(rho, 1)) for rho in result.states] fig, ax = plt.subplots(figsize=(10,5)) ax.plot(t, S1, label=r\u0026#39;$k = 0.1$\u0026#39;) ax.plot(t, S2, label=r\u0026#39;$k = 0.5$\u0026#39;) ax.plot(t, S3, label=r\u0026#39;$k = 1.0$\u0026#39;) ax.legend() ax.set_title(\u0026#39;Linear entropy of the mirror\u0026#39;) ax.set_xlabel(r\u0026#39;$t$\u0026#39;, fontsize=18) ax.set_ylabel(r\u0026#39;$S$\u0026#39;, fontsize=18) ax.set_xlim(0, t.max()); Since the dynamics here is undamped the quantum state is pure, and a nonzero entropy of a the subsystem of the mirror demonstrates that the mirror is entangled with the cavity field.\nCheck Hilbert space truncation As a check to make sure that we have use a sufficiently large Hilbert space in the calcuation above we plot the expectation value of the commutators $[a, a^\\dagger]$ and $[b , b^\\dagger]$ which should be very close to 1 if the Fock-state basis truncation that we used above is OK.\nfig, axes = plt.subplots(1, 2, figsize=(16,5)) axes[0].plot(t, C1_A, label=r\u0026#39;$k = 0.1$\u0026#39;) axes[0].plot(t, C2_A, label=r\u0026#39;$k = 0.5$\u0026#39;) axes[0].plot(t, C3_A, label=r\u0026#39;$k = 1.0$\u0026#39;) axes[0].legend() axes[0].set_title(\u0026#39;[a, a.dag()]\u0026#39;) axes[0].set_xlabel(r\u0026#39;$t$\u0026#39;, fontsize=18) axes[0].set_ylabel(r\u0026#39;$S$\u0026#39;, fontsize=18); axes[0].set_ylim(0, 1.1); axes[1].plot(t, C1_B, label=r\u0026#39;$k = 0.1$\u0026#39;) axes[1].plot(t, C2_B, label=r\u0026#39;$k = 0.5$\u0026#39;) axes[1].plot(t, C3_B, label=r\u0026#39;$k = 1.0$\u0026#39;) axes[1].legend() axes[1].set_title(\u0026#39;[b, b.dag()]]\u0026#39;) axes[1].set_xlabel(r\u0026#39;$t$\u0026#39;, fontsize=18) axes[1].set_ylabel(r\u0026#39;$S$\u0026#39;, fontsize=18) axes[1].set_ylim(0, 1.1); Figure 2 in Bose et al. The wigner function of the mirror for various times $t$.\nt = [0, pi/2, pi, 3*pi/2, 2*pi] result, C_A, C_B = solve_dynamics_undamped(r, 0.3, alpha, beta, t, N, M) fig, axes = plt.subplots(len(t), 2, figsize=(8,16)) for idx, rho in enumerate(result.states): rho_mirror = ptrace(rho, 1) plot_fock_distribution(rho_mirror, fig=fig, ax=axes[idx, 0]) plot_wigner(rho_mirror, fig=fig, ax=axes[idx, 1]) fig.tight_layout() The mirror wigner functions are always positive and the mirror therefore always in a classical state.\nFigure 3 in Bose et al. The wigner function of the cavity field at $t = 2\\pi$, for three different values of $k$.\nt = [0, 2*pi] k_vec = [0.5, 0.4082, 0.3536] states = [solve_dynamics_undamped(r, k, alpha, beta, t, 3*N, 3*M)[0].states[-1] for k in k_vec] fig, axes = plt.subplots(len(k_vec), 2, figsize=(8,12)) for idx, rho in enumerate(states): rho_cavity = ptrace(rho, 0) plot_fock_distribution(rho_cavity, fig=fig, ax=axes[idx, 0]) plot_wigner(rho_cavity, fig=fig, ax=axes[idx, 1]) fig.tight_layout() For these particular parameters the cavity field is prepared in superpositions of two, three and four coherent states, respectively.\nDamped dynamics # number of fock states in the cavity and mirror modes N = 10 M = 10 def solve_dynamics_damped(r, k, gamma, alpha, beta, t, N, M): wm = 1 w0 = r * wm g = k * wm a = tensor(destroy(N), identity(M)) b = tensor(identity(N), destroy(M)) H = w0 * a.dag() * a + wm * b.dag() * b - g * a.dag() * a * (b + b.dag()) psi0 = tensor(coherent(N, alpha), coherent(M, beta)) c_ops = [sqrt(gamma) * b] options = {\u0026#34;nsteps\u0026#34;: 15_000, \u0026#34;progress_bar\u0026#34;: \u0026#34;enhanced\u0026#34;} return mesolve(H, psi0, t, c_ops, options=options) Figure 6 in Bose et al. gamma = 1.0 alpha = 2 beta = 0 t = linspace(0, 2 * pi, 25) S1 = [entropy_linear(ptrace(rho, 1)) for rho in solve_dynamics_damped(r, 0.1, gamma, alpha, beta, t, N, M).states] [** 8% ] Elapsed 0.02s / Remaining 00:00:00:00 Total run time: 0.18s*] Elapsed 0.18s / Remaining 00:00:00:00 S2 = [entropy_linear(ptrace(rho, 1)) for rho in solve_dynamics_damped(r, 0.5, gamma, alpha, beta, t, N, M).states] Total run time: 0.34s*] Elapsed 0.34s / Remaining 00:00:00:00 S3 = [entropy_linear(ptrace(rho, 1)) for rho in solve_dynamics_damped(r, 1.0, gamma, alpha, beta, t, N, M).states] Total run time: 0.69s*] Elapsed 0.69s / Remaining 00:00:00:00 fig, ax = plt.subplots(figsize=(10,5)) ax.plot(t, S1, label=r\u0026#39;$k = 0.1$\u0026#39;) ax.plot(t, S2, label=r\u0026#39;$k = 0.5$\u0026#39;) ax.plot(t, S3, label=r\u0026#39;$k = 1.0$\u0026#39;) ax.legend() ax.set_title(\u0026#39;Linear entropy of the mirror\u0026#39;) ax.set_xlabel(r\u0026#39;$t$\u0026#39;, fontsize=18) ax.set_ylabel(r\u0026#39;$S$\u0026#39;, fontsize=18) ax.set_xlim(0, t.max()); Figure 7 in Bose et al. t = [0, 2*pi] k = 0.5 alpha = beta = 2 gamma_vec = [0.001, 0.01, 0.1, 1.0] states = [solve_dynamics_damped(r, k, gamma, alpha, beta, t, 3*N, 2*M).states[-1] for gamma in gamma_vec] Total run time: 38.77s*] Elapsed 38.77s / Remaining 00:00:00:00 Total run time: 45.80s*] Elapsed 45.80s / Remaining 00:00:00:00 Total run time: 51.90s*] Elapsed 51.90s / Remaining 00:00:00:00 Total run time: 53.20s*] Elapsed 53.20s / Remaining 00:00:00:00 fig, axes = plt.subplots(len(gamma_vec), 2, figsize=(8,16)) for idx, rho in enumerate(states): rho_cavity = ptrace(rho, 0) plot_fock_distribution(rho_cavity, fig=fig, ax=axes[idx, 0]) plot_wigner(rho_cavity, fig=fig, ax=axes[idx, 1]) fig.tight_layout() Versions %reload_ext version_information %version_information numpy, scipy, matplotlib, qutip SoftwareVersionPython3.13.5 64bit [GCC 15.1.1 20250521 (Red Hat 15.1.1-2)]IPython9.2.0OSLinux 6.14.11 300.fc42.x86\\_64 x86\\_64 with glibc2.41numpy2.3.1scipy1.16.0matplotlib3.10.3qutip5.2.0Mon Jul 14 09:01:53 2025 CEST ","date":"July 14, 2025","hero":"/posts/phys_rev_a_56_4175_1997/preview.png","permalink":"https://oameye.github.io/posts/phys_rev_a_56_4175_1997/","summary":"Reproducing the results of Bose et al. on nonclassical states in cavities with a moving mirror.","tags":["python","Reproduced paper","qutip"],"title":"Preparation of nonclassical states in cavities with a moving mirror"},{"categories":null,"contents":"This notebook demonstrates the computation of Quantum Fisher Information (QFI) for a driven-dissipative Kerr Parametric Oscillator (KPO) using automatic differentiation. The QFI quantifies the ultimate precision limit for parameter estimation in quantum systems.\nWe import the necessary packages for quantum simulations and automatic differentiation:\nusing QuantumToolbox # Quantum optics simulations using DifferentiationInterface # Unified automatic differentiation interface using SciMLSensitivity # Allows for ODE sensitivity analysis using FiniteDiff # Finite difference methods using LinearAlgebra # Linear algebra operations using CairoMakie # Plotting CairoMakie.activate!(type = \u0026#34;svg\u0026#34;) System Parameters and Hamiltonian The KPO system is governed by the Hamiltonian: $$H = -p_1 a^\\dagger a + K (a^\\dagger)^2 a^2 - G (a^\\dagger a^\\dagger + a a)$$\nwhere:\n$p_1$ is the parameter we want to estimate (detuning) $K$ is the Kerr nonlinearity $G$ is the parametric drive strength $\\gamma$ is the decay rate function final_state(p, t) G, K, γ = 0.002, 0.001, 0.01 N = 20 # cutoff of the Hilbert space dimension a = destroy(N) # annihilation operator coef(p,t) = - p[1] H = QobjEvo(a\u0026#39; * a , coef) + K * a\u0026#39; * a\u0026#39; * a * a - G * (a\u0026#39; * a\u0026#39; + a * a) c_ops = [sqrt(γ)*a] ψ0 = fock(N, 0) # initial state tlist = range(0, 2000, 100) sol = mesolve(H, ψ0, tlist, c_ops; params = p, progress_bar = Val(false), saveat = [t]) return sol.states[end].data end final_state (generic function with 1 method) Quantum Fisher Information Calculation The QFI is computed using the symmetric logarithmic derivative (SLD). For a density matrix $\\rho(\\theta)$ parametrized by $\\theta$:\n$$F_Q = \\text{Tr}[\\partial_\\theta \\rho \\cdot L]$$\nwhere $L$ is the SLD satisfying: $\\partial_\\theta \\rho = \\frac{1}{2}(\\rho L + L \\rho)$\nfunction compute_fisher_information(ρ, dρ) reg = 1e-12 * I # Add small regularization to avoid numerical issues with zero eigenvalues ρ_reg = ρ + reg L = sylvester(ρ_reg, ρ_reg, -2*dρ) # This is a Sylvester equation: ρL + Lρ = 2*dρ F = real(tr(dρ * L)) # Fisher information F = Tr(dρ * L) return F end compute_fisher_information (generic function with 1 method) Automatic Differentiation Setup We use finite differences through DifferentiationInterface.jl to compute the derivative of the quantum state with respect to the parameter. This is a key step that enables efficient QFI computation without manual derivative calculations.\nfinal_state([0], 100) # Test the system state(p) = final_state(p, 2000) # Define state function for automatic differentiation ρ, dρ = DifferentiationInterface.value_and_jacobian(state, AutoFiniteDiff(), [0.0]) dρ = QuantumToolbox.vec2mat(vec(dρ)) # Reshape the derivative back to matrix form qfi_final = compute_fisher_information(ρ, dρ) # Compute QFI at final time println(\u0026#34;QFI at final time: \u0026#34;, qfi_final) QFI at final time: 19795.821946511165 Time Evolution of Quantum Fisher Information Now we compute how the QFI evolves over time to understand the optimal measurement time for parameter estimation:\nts = range(0, 2000, 100) QFI_t = map(ts) do t state(p) = final_state(p, t) ρ, dρ = DifferentiationInterface.value_and_jacobian(state, AutoFiniteDiff(), [0.0]) dρ = QuantumToolbox.vec2mat(vec(dρ)) compute_fisher_information(ρ, dρ) end println(\u0026#34;QFI computed for \u0026#34;, length(ts), \u0026#34; time points\u0026#34;) QFI computed for 100 time points Visualization Plot the time evolution of the Quantum Fisher Information:\nfig = Figure() ax = Axis( fig[1,1], xlabel = \u0026#34;Time\u0026#34;, ylabel = \u0026#34;Quantum Fisher Information\u0026#34; ) lines!(ax, ts, QFI_t) fig Version Information using InteractiveUtils InteractiveUtils.versioninfo() Julia Version 1.10.10 Commit 95f30e51f41 (2025-06-27 09:51 UTC) Build Info: Official https://julialang.org/ release Platform Info: OS: Linux (x86_64-linux-gnu) CPU: 12 × AMD Ryzen 5 5600X 6-Core Processor WORD_SIZE: 64 LIBM: libopenlibm LLVM: libLLVM-15.0.7 (ORCJIT, znver3) Threads: 10 default, 0 interactive, 5 GC (on 12 virtual cores) Environment: JULIA_EDITOR = code JULIA_VSCODE_REPL = 1 JULIA_NUM_THREADS = 10 using Pkg Pkg.status() Status `/var/home/oameye/Documents/website/content/posts/Quantum_Fisher_Information/Project.toml` ⌃ [13f3f980] CairoMakie v0.13.10 [a0c0ee7d] DifferentiationInterface v0.7.2 [6a86dc24] FiniteDiff v2.27.0 [98b081ad] Literate v2.20.1 [6c2fb7c5] QuantumToolbox v0.32.1 [1ed8b502] SciMLSensitivity v7.87.0 [37e2e46d] LinearAlgebra Info Packages marked with ⌃ have new versions available and may be upgradable. This page was generated using Literate.jl.\n","date":"July 13, 2025","hero":"/posts/quantum_fisher_information/preview.svg","permalink":"https://oameye.github.io/posts/quantum_fisher_information/","summary":"Computation of Quantum Fisher Information for a driven-dissipative Kerr Parametric Oscillator using automatic differentiation.","tags":["Julia","Tutorial","Automatic Differentiation"],"title":"Quantum Fisher Information with automatic differentiation"},{"categories":["reproduced_paper"],"contents":"using LatticeModels, Plots; LM = LatticeModels using QuantumOptics using Plots.Measures default(fmt=:png, fontfamily=\u0026#34;computer modern\u0026#34;, titlefont=\u0026#34;computer modern\u0026#34;, tickfont=\u0026#34;computer modern\u0026#34;; linewidth=2, legend_position=:best ) We want to reproduce the Bloch oscillation in a ring resonator. A ring resonator with a dynamic refractive index modulation can exhibit Bloch oscillation of light along the frequency axis, as a result of an effective force for photons induced by the modulation, as is shown in Yuan et al (2016).\nFurthermore, we want to show that one can deduce directional transport on the frequency axis by switching the detuning periodically.\nWe will implement the model ad deduced in Yuan et al (2016): $$ \\tilde{H}=g \\sum_m\\left(c_m^{\\dagger} c_{m+1}+c_{m+1}^{\\dagger} c_m\\right)+\\sum_m m \\Delta(t) c_m^{\\dagger} c_m, $$ where $m$ is the resonant mode of the waveguide in the resonator, $g$ is the strength of the modulation, and $\\Delta$ is the detuning of the resonant frequency of the waveguide from the modulation frequency.\nWe start by implementing a lattice of 100 sites, i.e., we consider 100 modes of the waveguide. The lattice will have reflective boundary conditions. Furthermore, the tight binding system has one particle and a chemical potential of zero. No extra particles can be added to the system.\nsize=100 lattice = SquareLattice(size, 1) x_basis = PositionBasis(0, size, size) sample = Sample(lattice, boundaries=BoundaryConditions(1 =\u0026gt; true, 2 =\u0026gt; true)) system = System(sample, μ=0.0, statistics=LM.OneParticle) LatticeModels.FilledZones{Sample{Nothing, SquareLattice{2}, Nothing, BoundaryConditions{Tuple{TwistedBoundary, TwistedBoundary}}}}(Sample{Nothing, SquareLattice{2}, Nothing, BoundaryConditions{Tuple{TwistedBoundary, TwistedBoundary}}}(nothing, SquareLattice{2}((100, 1), LatticeModels.Bravais{2, 1}([1.0 0.0; 0.0 1.0], [0.0; 0.0;;]), Bool[1, 1, 1, 1, 1, 1, 1, 1, 1, 1 … 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), BoundaryConditions{Tuple{TwistedBoundary, TwistedBoundary}}((TwistedBoundary(1, 0.0), TwistedBoundary(2, 0.0))), nothing), 0.0, LatticeModels.OneParticle) We implement the time dependent Hamiltonian where switch the detuning periodically between -$\\Delta$ and +$\\Delta$ with a period of $T=1$.\ng = 2; Δ = 2 function h(t, g, Δ; switch = t -\u0026gt; isodd(floor(t)) ? -1 : 1) build_hamiltonian(lattice, lattice .|\u0026gt; (site -\u0026gt; Δ* switch(t)*site.coords[1]), g =\u0026gt; SiteOffset(axis=1) ) end H0 = h(0, g, Δ) Hamiltonian(dim=100x100) basis: LatticeBasis{SquareLattice{2}}(100, SquareLattice{2}((100, 1), LatticeModels.Bravais{2, 1}([1.0 0.0; 0.0 1.0], [0.0; 0.0;;]), Bool[1, 1, 1, 1, 1, 1, 1, 1, 1, 1 … 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])) sparse([1, 2, 1, 2, 3, 2, 3, 4, 3, 4 … 97, 98, 97, 98, 99, 98, 99, 100, 99, 100], [1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9, 10, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14, 15, 15, 15, 16, 16, 16, 17, 17, 17, 18, 18, 18, 19, 19, 19, 20, 20, 20, 21, 21, 21, 22, 22, 22, 23, 23, 23, 24, 24, 24, 25, 25, 25, 26, 26, 26, 27, 27, 27, 28, 28, 28, 29, 29, 29, 30, 30, 30, 31, 31, 31, 32, 32, 32, 33, 33, 33, 34, 34, 34, 35, 35, 35, 36, 36, 36, 37, 37, 37, 38, 38, 38, 39, 39, 39, 40, 40, 40, 41, 41, 41, 42, 42, 42, 43, 43, 43, 44, 44, 44, 45, 45, 45, 46, 46, 46, 47, 47, 47, 48, 48, 48, 49, 49, 49, 50, 50, 50, 51, 51, 51, 52, 52, 52, 53, 53, 53, 54, 54, 54, 55, 55, 55, 56, 56, 56, 57, 57, 57, 58, 58, 58, 59, 59, 59, 60, 60, 60, 61, 61, 61, 62, 62, 62, 63, 63, 63, 64, 64, 64, 65, 65, 65, 66, 66, 66, 67, 67, 67, 68, 68, 68, 69, 69, 69, 70, 70, 70, 71, 71, 71, 72, 72, 72, 73, 73, 73, 74, 74, 74, 75, 75, 75, 76, 76, 76, 77, 77, 77, 78, 78, 78, 79, 79, 79, 80, 80, 80, 81, 81, 81, 82, 82, 82, 83, 83, 83, 84, 84, 84, 85, 85, 85, 86, 86, 86, 87, 87, 87, 88, 88, 88, 89, 89, 89, 90, 90, 90, 91, 91, 91, 92, 92, 92, 93, 93, 93, 94, 94, 94, 95, 95, 95, 96, 96, 96, 97, 97, 97, 98, 98, 98, 99, 99, 99, 100, 100], ComplexF64[2.0+0.0im, 2.0+0.0im, 2.0-0.0im, 4.0+0.0im, 2.0+0.0im, 2.0-0.0im, 6.0+0.0im, 2.0+0.0im, 2.0-0.0im, 8.0+0.0im … 194.0+0.0im, 2.0+0.0im, 2.0-0.0im, 196.0+0.0im, 2.0+0.0im, 2.0-0.0im, 198.0+0.0im, 2.0+0.0im, 2.0-0.0im, 200.0+0.0im], 100, 100) As initial condition, we choose a Gaussian lattice density profile with a width of $\\sigma=5$:\nψx = gaussianstate(x_basis, div(size, 3), 0.0, 5) ψl = Ket(H0.basis_r, ψx.data) P0 = Operator(ψl.basis, ψl.data * ψl.data\u0026#39;) d = lattice_density(P0) plot(d.values) g = 2; Δ = 2 density_rec = [] @evolution show_progress=false {H := h(t, g, Δ), P0 --\u0026gt; H --\u0026gt; P} for t in 0:0.01:20 d = lattice_density(P) .|\u0026gt; real push!(density_rec,d.values) end p1 = heatmap(hcat(density_rec...)\u0026#39;, xlabel=\u0026#34;lattice site\u0026#34;, ylabel=\u0026#34;time\u0026#34;, title=\u0026#34;Δ=±$(Δ)\u0026#34;, colorbar=false) density_rec = [] @evolution show_progress=false {H := h(t, g, Δ, switch= x-\u0026gt; 1), P0 --\u0026gt; H --\u0026gt; P} for t in 0:0.01:20 d = lattice_density(P) .|\u0026gt; real push!(density_rec,d.values) end p2 = heatmap(hcat(density_rec...)\u0026#39;, xlabel=\u0026#34;lattice site\u0026#34;, ylabel=\u0026#34;time\u0026#34;, title=\u0026#34;Δ=$(Δ)\u0026#34;, colorbar=false) density_rec = [] @evolution show_progress=false {H := h(t, g, Δ, switch= x-\u0026gt; -1), P0 --\u0026gt; H --\u0026gt; P} for t in 0:0.01:20 d = lattice_density(P) .|\u0026gt; real push!(density_rec,d.values) end p3 = heatmap(hcat(density_rec...)\u0026#39;, xlabel=\u0026#34;lattice site\u0026#34;, ylabel=\u0026#34;time\u0026#34;, title=\u0026#34;Δ=-$(Δ)\u0026#34;); l = @layout [a b c{0.42w}] plot(p1, p2, p3, layout=l, size=(1200,400), plot_title=\u0026#34;Normalised lattice density\u0026#34;, margin=5mm, plot_titlevspan=0.1) # savefig(plotsdir(\u0026#34;lattice_density.png\u0026#34;)) plot(p2, xlim=(20, 50)) function evolution_operator(h, t) H = h(t) ev_op = Operator(basis(H), H.data) LM.evolution_operator!(ev_op, H, t) return ev_op end time_hamiltonian = t -\u0026gt; h(t, 2, 2) ev_op = evolution_operator(time_hamiltonian, 2.1) Operator(dim=100x100) basis: LatticeBasis{SquareLattice{2}}(100, SquareLattice{2}((100, 1), LatticeModels.Bravais{2, 1}([1.0 0.0; 0.0 1.0], [0.0; 0.0;;]), Bool[1, 1, 1, 1, 1, 1, 1, 1, 1, 1 … 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))sparse([1, 2, 3, 4, 5, 6, 1, 2, 3, 4 … 97, 98, 99, 100, 95, 96, 97, 98, 99, 100], [1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 97, 97, 97, 97, 97, 97, 97, 97, 97, 98, 98, 98, 98, 98, 98, 98, 98, 99, 99, 99, 99, 99, 99, 99, 100, 100, 100, 100, 100, 100], ComplexF64[0.9999327113815735 - 0.00820266501446412im, -0.00010093141833268 - 0.00820229703303101im, -3.364034731125e-5 + 5.5196054197e-7im, 1.88653881e-9 + 9.197841102e-8im, 1.8861004e-10 - 4.64309e-12im, 0.0 - 3.0954e-13im, -0.00010093141833268 - 0.00820229703303101im, 0.9997981396159296 - 0.01640441008695316im, -0.00016821022641636 - 0.00820110113353606im, -3.363449908477e-5 + 8.2789113194e-7im … -2.334602203862e-5 + 2.422660081674e-5im, -0.00592992240212792 - 0.00566766043323879im, 0.6879228134802496 - 0.7256911377053686im, -0.00597628217655804 - 0.00561888913526103im, -2.2117e-13 - 2.1053e-13im, 1.3091519e-10 - 1.3586203e-10im, 6.650629582e-8 + 6.356493028e-8im, -2.314663406714e-5 + 2.441743145251e-5im, -0.00597628217655804 - 0.00561888913526103im, 0.6819696779377588 - 0.731334444272082im], 100, 100) ","date":"October 23, 2023","hero":"/posts/bloch_oscillations/preview.png","permalink":"https://oameye.github.io/posts/bloch_oscillations/","summary":"We show how a ring resonator with a dynamic refractive index modulation can exhibit Bloch oscillation of light along the frequency axis, as a result of an effective force for photons induced by the modulation.","tags":["Julia","Tutorial","Reproduced paper"],"title":"Bloch oscillation in a dynamically modulated ring resonator"},{"categories":["reproduced_papers"],"contents":"In this notebook, we try to understand the parametron, also known as Kerr Parametric Oscillator (KPO). We will begin with a system we already understand very well and build up are knowledge by slowly encreasing the complexity of the system.\nThe sources used in the endeavour are:\nT. Heugel, Parametrons: From Sensing to Optimization Machines, Doctoral thesis at ETH Zürich, 2022. J. Košata, J. del Pino, T. Heugel, and O. Zilberberg, HarmonicBalance.Jl: A Julia Suite for Nonlinear Dynamics Using Harmonic Balance, SciPost Phys. Codebases 6 (2022). O. Zilberberg and A. Eichler, Classical and Quantum Parametric Phenomena (2022). J. Košata, Spatial and Temporal Mode Engineering in Nonlinear Media, Doctoral thesis at ETH Zürich, 2022. To run this notebook the following julia environment was used:\nusing DrWatson versioninfo() Julia Version 1.9.0 Commit 8e63055292 (2023-05-07 11:25 UTC) Platform Info: OS: Windows (x86_64-w64-mingw32) CPU: 12 × AMD Ryzen 5 5600X 6-Core Processor WORD_SIZE: 64 LIBM: libopenlibm LLVM: libLLVM-14.0.6 (ORCJIT, znver3) Threads: 10 on 12 virtual cores Environment: JULIA_NUM_THREADS = 10 And the following packages are needed:\nusing HarmonicBalance, OrdinaryDiffEq, ModelingToolkit HB_settings = (:threading =\u0026gt; true, :show_progress =\u0026gt; false) using Plots, LaTeXStrings, Latexify, Measures import Base.@kwdef default(fontfamily=\u0026#34;computer modern\u0026#34;, titlefont=\u0026#34;computer modern\u0026#34;, tickfont=\u0026#34;computer modern\u0026#34;, legend = :best, linewidth = 2, show = true, fmt = :svg) plot_size = (750, 350); margin = 5mm; using Pkg; Pkg.status( [\u0026#34;HarmonicBalance\u0026#34;, \u0026#34;OrdinaryDiffEq\u0026#34;, \u0026#34;ModelingToolkit\u0026#34;, \u0026#34;Plots\u0026#34;, \u0026#34;Latexify\u0026#34;, \u0026#34;DrWatson\u0026#34;, \u0026#34;LaTeXStrings\u0026#34;, \u0026#34;Measures\u0026#34;] ) DrWatson v2.12.5 HarmonicBalance v0.6.4 LaTeXStrings v1.3.0 Latexify v0.15.21 Measures v0.3.2 ModelingToolkit v8.46.1 OrdinaryDiffEq v6.51.2 Plots v1.38.12 Harmonic Oscillator We begin with the simple harmonic oscillator and slowly build up to the parametron. We make use of the differential equation solver of Julia to analyse the system.\n@variables t x(t) # symbolic variables @parameters ω ω₀ F γ Dₜ = Differential(t) @named sys = ODESystem([Dₜ(Dₜ(x)) ~ - ω₀^2*x - γ*Dₜ(x) + F*cos(ω*t)], t, [x], [ω₀, ω, F, γ]) sys = ode_order_lowering(sys) $$ \\begin{aligned} \\frac{\\mathrm{d} xˍt\\left( t \\right)}{\\mathrm{d}t} =\u0026amp; F \\cos\\left( t \\omega \\right) - \\gamma xˍt\\left( t \\right) - \\omega_0^{2} x\\left( t \\right) \\ \\frac{\\mathrm{d} x\\left( t \\right)}{\\mathrm{d}t} =\u0026amp; xˍt\\left( t \\right) \\end{aligned} $$\nSimple Harmonic Oscillator Let us first plot the resonator without any damping ($\\gamma=0$) or external drive ($F=0$):\nx0 = [x =\u0026gt; 1.0, Dₜ(x) =\u0026gt; 0]; tspan = (0.0, 200.0) fixed = [ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.0, F =\u0026gt; 0.0, ω =\u0026gt; 0.0] 4-element Vector{Pair{Num, Float64}}: ω₀ =\u0026gt; 1.0 γ =\u0026gt; 0.0 F =\u0026gt; 0.0 ω =\u0026gt; 0.0 prob = ODEProblem(sys, x0, tspan, fixed) tr = solve(prob, Tsit5(), saveat=0.1); plot1 = plot(tr.t , tr[1,:], xlabel=\u0026#34;t\u0026#34;, ylabel=\u0026#34;x(t)\u0026#34;, legend=false, rightmargin=0mm) plot2 = plot(tr, idxs=(1,2), xlabel=\u0026#34;x(t)\u0026#34;, ylabel=\u0026#34;v(t)\u0026#34;, legend=false, framestyle = :origin, aspect_ratio=1, leftmargin=0mm) plot(plot1, plot2, size = plot_size, margin = margin, legend=false) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e In general, it is useful the look at the system in phase space. Note, the path is periodic.\nDamping One can add damping to make it make realistic ($\\gamma \u0026gt; 0$). In general, we have three regimes:\n$$ \\begin{cases} \\omega_0 \u0026gt; \\gamma/2 \\quad \\text{(underdamped)} \\ \\omega_0 = \\gamma/2 \\quad \\text{(citically damped)} \\ \\omega_0 \u0026lt; \\gamma/2 \\quad \\text{(overdamped)}\\ \\end{cases} \\qquad \\underbrace{\\quad\\Longrightarrow\\quad}_{\\gamma = \\omega_0/Q} \\qquad \\begin{cases} Q \u0026gt; 1/2 \\quad \\text{(underdamped)} \\ Q = 1/2 \\quad \\text{(citically damped)} \\ Q \u0026lt; 1/2 \\quad \\text{(overdamped)}\\ \\end{cases} $$\n$Q$ is called the quality factor which characterizes the damping.\nu0 = [x =\u0026gt; 1.0, Dₜ(x) =\u0026gt; 0]; tspan = (0.0, 200.0); p1 = [ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.1, F =\u0026gt; 0.0, ω =\u0026gt; 1.0] p2 = [ω₀ =\u0026gt; 1.0, γ =\u0026gt; 2.0, F =\u0026gt; 0.0, ω =\u0026gt; 1.0] p3 = [ω₀ =\u0026gt; 1.0, γ =\u0026gt; 5.0, F =\u0026gt; 0.0, ω =\u0026gt; 1.0] prob = [ODEProblem(sys, u0, tspan, p) for p in [p1, p2, p3]] tr = [solve(p, Tsit5(), saveat=0.1) for p in prob]; plot1 = plot(;xlabel=\u0026#34;t\u0026#34;, ylabel=\u0026#34;x(t)\u0026#34;, legend=false) plot2 = plot(;xlabel=\u0026#34;x(t)\u0026#34;, ylabel=\u0026#34;v(t)\u0026#34;, framestyle = :origin, aspect_ratio=1) for (sol, lab) in zip(tr, [\u0026#34;underdamped\u0026#34;, \u0026#34;criticaly damped\u0026#34;, \u0026#34;overdamped\u0026#34;]) plot!(plot1, sol.t , sol[1,:]) plot!(plot2, sol, idxs=(1,2), lims = :symmetric, label = lab) end plot(plot1, plot2, size = plot_size, margin = margin) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e We observe a ringdown process, i.e., exponential weakening of the oscillation amplitude.\nDamped driven harmonic oscillator Let us make the harmonic oscillator complete by adding external driving ($F\u0026gt;0$) with frequency $\\omega$.\nu0 = [x =\u0026gt; 1.0, Dₜ(x) =\u0026gt; 0]; tspan = (0.0, 100); p1 = [ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.1, F =\u0026gt; 0.01, ω =\u0026gt; 1.0] p2 = [ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.1, F =\u0026gt; 0.1, ω =\u0026gt; 1.0] p3 = [ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.1, F =\u0026gt; 0.2, ω =\u0026gt; 1.0] prob = [ODEProblem(sys, u0, tspan, p) for p in [p1, p2, p3]] tr = [solve(p, Tsit5(), saveat=0.1) for p in prob]; plot1 = plot(;xlabel=\u0026#34;t\u0026#34;, ylabel=\u0026#34;x(t)\u0026#34;, legend=false) plot2 = plot(;xlabel=\u0026#34;x(t)\u0026#34;, ylabel=\u0026#34;v(t)\u0026#34;, framestyle = :origin, aspect_ratio=:equal) for (sol, lab) in zip(tr, [\u0026#34;F = 0.01\u0026#34;, \u0026#34;F = 0.1\u0026#34;, \u0026#34;F = 0.2\u0026#34;]) plot!(plot1, sol.t , sol[1,:]) plot!(plot2, sol, idxs=(1,2), lims = :symmetric, label = lab) end plot(plot1, plot2, size = plot_size, margin = margin) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e The amplitude of the steady state oscillation depends on $F$, as expected.\nu0 = [x =\u0026gt; 1.0, Dₜ(x) =\u0026gt; 0]; tspan = (0.0, 2000); p1 = [ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.2, F =\u0026gt; 0.08, ω =\u0026gt; 1.0] p2 = [ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.2, F =\u0026gt; 0.08, ω =\u0026gt; 0.7] p3 = [ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.2, F =\u0026gt; 0.08, ω =\u0026gt; 0.5] prob = [ODEProblem(sys, u0, tspan, p) for p in [p1, p2, p3]] tr = [solve(p, Tsit5(), saveat=0.1) for p in prob]; plot1 = plot(;xlabel=\u0026#34;t\u0026#34;, ylabel=\u0026#34;x(t)\u0026#34;, legend=false) plot2 = plot(;xlabel=\u0026#34;x(t)\u0026#34;, ylabel=\u0026#34;v(t)\u0026#34;, framestyle = :origin, aspect_ratio=1) for (sol, lab) in zip(tr, [\u0026#34;ω = 1.0\u0026#34;, \u0026#34;ω = 0.7\u0026#34;, \u0026#34;ω = 0.2\u0026#34;]) plot!(plot1, sol.t , sol[1,:]) plot!(plot2, sol, idxs=(1,2), lims = :symmetric, label = lab) end plot(plot1, plot2, size = plot_size, margin = margin) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e But also on the detuning, i.e., $|\\omega_0-\\omega|$, of the natural frequency $\\omega_0$ and driving frequency $\\omega$.\nFrequency sweep and harmonic reponse The harmonic oscillator has only one frequency response, in particular that of the drive $\\omega_d$. Indeed: $$ \\ddot{x}(t)+\\gamma\\dot{x}(t)+\\omega_0^2x=F\\cos(\\omega_d t + \\theta) \\quad \\underbrace{\\quad\\Longrightarrow\\quad}_{\\text{Fourier w.r.t. $\\omega$}} \\quad \\tilde{x}(\\omega) = \\frac{F}{\\omega_0^2-\\omega^2+i\\omega\\gamma}\\left[\\delta(\\omega+\\omega_d)+\\delta(\\omega-\\omega_d)\\right] $$ Let us look at the steady state. For this we use Harmonic Balance method. Clearly, in the long-time limit, our system will behave as a harmonic, i.e., we use the ansatz $x(t)=A\\cos(\\omega t + \\phi)$. Hence, we can write: $$ x(t) = A \\cos(\\phi) \\cos(\\omega t) - A \\sin(\\phi) \\sin(\\omega t) = u(A, \\phi)\\cos(\\omega t) + v(A, \\phi) \\sin(\\omega t) $$ where we used some the sum-to-product trigonometric identities and defined quadratures $u$ and $v$. From, know one we examine our system in terms of the quadratures, i.e., in the rotating frame.\nClearly, for the whole time evolution the amplitude $A$ and phase $\\phi$ will not be constants. Hence, in general, we say that the quadratures depend on the slow time $T$, where the $\\cos$ and $\\sin$ are dependent on fast time $t$.\n@parameters ω ω₀ F γ λ θ α ψ η natural_equation = d(d(x, t), t) + γ*d(x, t) + ω₀^2*(1-λ*cos(2*ω*t + ψ))*x + α*x^3 + η*d(x, t)*x^2 forces = F*cos(ω*t + θ) diff_eq = DifferentialEquation(natural_equation ~ forces, x) add_harmonic!(diff_eq, x, ω); harmonic = get_harmonic_equations(diff_eq); x0 = [1.0, 0.0]; tspan = (0.0, 2000.0) fixed = (ω =\u0026gt; 1.1, ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; 0.01, α =\u0026gt; 0.0, λ =\u0026gt; 0.0, η =\u0026gt; 0.0, θ =\u0026gt; 0.0, ψ =\u0026gt; 0.0) ode_problem = ODEProblem(harmonic, fixed, x0 = x0, timespan = tspan) tr = solve(ode_problem, Tsit5(), saveat=0.1); p1 = plot(tr, \u0026#34;u1\u0026#34;, harmonic, size = plot_size) plot!(tr, \u0026#34;v1\u0026#34;, harmonic) p2 = plot(tr, [\u0026#34;u1\u0026#34;, \u0026#34;v1\u0026#34;], harmonic, framestyle=:origin, aspect_ratio=1, lims=:symmetric) plot!([x0[1]],[x0[2]], markers=:true, line=false) plot!([tr.u[end][1]],[tr.u[end][2]], markers=:true, line=false, size = plot_size, margin = margin) plot(p1, p2) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e Notice that one of the quadratures, $u_1$, is non-zero for large $t$, which means the system oscillates with frequency $\\omega_0$.\nIn experiment, the system is often analysed with frequency sweeps, i.e., we look at the response of the oscillators when changing the external driving frequency adiabatically.\nvaried = ω =\u0026gt; range(0.9, 1.1, 500); listγ = pairs([0.01, 0.02, 0.03]); results = Vector(undef, length(listγ)) plotγ = plot() for (i,gamma) in listγ fixed = (ω₀ =\u0026gt; 1.0, γ =\u0026gt; gamma, F =\u0026gt; 0.01, α =\u0026gt; 0.0, λ =\u0026gt; 0.0, η =\u0026gt; 0.0, θ =\u0026gt; 0.0, ψ =\u0026gt; 0.0) results[i] = get_steady_states(harmonic, varied, fixed) plot!(results[i], x=\u0026#34;ω/ω₀\u0026#34;, y=\u0026#34;sqrt(u1^2 + v1^2)\u0026#34;, color = i == 1 ? :black : i, label=\u0026#34;γ = $gamma\u0026#34;) end listF = pairs([0.01, 0.02, 0.03]) results = Vector(undef, length(listF)) plotF = plot() for (i,force) in listγ fixed = (ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; force, α =\u0026gt; 0.0, λ =\u0026gt; 0.0, η =\u0026gt; 0.0, θ =\u0026gt; 0.0, ψ =\u0026gt; 0.0) results[i] = get_steady_states(harmonic, varied, fixed) plot!(results[i], x=\u0026#34;ω/ω₀\u0026#34;, y=\u0026#34;sqrt(u1^2 + v1^2)\u0026#34;, color = i == 1 ? :black : i, label=\u0026#34;F = $force\u0026#34;) end plot!(plotF, plotγ;legend = :best, size = plot_size, margin = margin) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e The resonant peak has a Lorentzian shape, where the height is affected by $\\gamma$ and $F$ and the peak maximum is at $\\omega_d=\\omega_0 \\sqrt{1-\\gamma^2 / 2 \\omega_0^2}$, i.e., the peak shifts depending on $\\gamma$.\nDuffing Oscillator @variables t x(t) # symbolic variables @parameters ω ω₀ F γ α Dₜ = Differential(t) eq = Dₜ(Dₜ(x)) ~ - ω₀^2*x - γ*Dₜ(x) -α*x^3 + F*cos(ω*t) @named sys = ODESystem([eq], t, [x], [ω₀, ω, F, γ, α]) sys = ode_order_lowering(sys) $$ \\begin{align} \\frac{\\mathrm{d} xˍt\\left( t \\right)}{\\mathrm{d}t} =\u0026amp; F \\cos\\left( t \\omega \\right) - \\left( x\\left( t \\right) \\right)^{3} \\alpha - \\gamma xˍt\\left( t \\right) - \\omega_0^{2} x\\left( t \\right) \\ \\frac{\\mathrm{d} x\\left( t \\right)}{\\mathrm{d}t} =\u0026amp; xˍt\\left( t \\right) \\end{align} $$\nHarmonics and bifurcations The equation of motion for the displacement $x(t)$ reads\n\\begin{align*} \\underbrace{\\ddot{x}(t)+\\gamma \\dot{x}(t)+\\omega_0^2 x(t)}{\\text {damped harmonic oscillator }}+\\underbrace{\\alpha x(t)^3}{\\text {Duffing coefficient }}=\\underbrace{F \\cos (\\omega t)}_{\\text {periodic drive }} \\end{align*}\nFor $\\alpha=0$, the system becomes linear and responds precisely at the drive frequency, so that $x(t)=X \\cos (\\omega t+\\phi)$, where $X$ and $\\phi$ can be found analytically. For $\\alpha \\neq 0$ this is no longer possible. We can obtain some intuition by treating $\\alpha$ perturbatively, i.e., by solving \\begin{align*} \\ddot{x}(t)+\\gamma \\dot{x}(t)+\\omega_0^2 x(t)+\\epsilon \\alpha x(t)^3=F \\cos (\\omega t) \\end{align*} for small $\\epsilon$. To zeroth order, the response of the system is $x_0(t)=X_0 \\cos \\left(\\omega t+\\phi_0\\right)$. Expanding $x(t)=x_0(t)+\\epsilon x_1(t)$, we find that the perturbation $x_1(t)$ satisfies to first order \\begin{align*} \\ddot{x}_1(t)+\\gamma \\dot{x}_1(t)\\left[\\omega_0^2+\\frac{3 \\alpha X_0^2}{4}\\right] x_1(t)=-\\frac{\\alpha X_0^3}{4} \\cos \\left(3 \\omega t+3 \\phi_0\\right), \\end{align*} which gives a response of the form $x_1(t)=X_1 \\cos \\left(3 \\omega t+\\phi_1\\right)$. Clearly, the oscillator now responds not only at frequency $\\omega$, but also at $3 \\omega$ ! This effect is known as high harmonic generation or more generally frequency conversion. By continuing the procedure to higher orders, we eventually obtain an infinity of harmonics present in the response. In general, there is no analytical solution to such problems.\nx0 = [1.0, 0.0]; tspan = (0.0, 1500.0) fixed = (ω =\u0026gt; 1.1, ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; 0.01, α =\u0026gt; 0.0, λ =\u0026gt; 0.0, η =\u0026gt; 0.0, θ =\u0026gt; 0.0, ψ =\u0026gt; 0.0) ode_problem = ODEProblem(harmonic, fixed, x0 = x0, timespan = tspan) tr = solve(ode_problem, Tsit5(), saveat=0.1); p1 = plot(tr, \u0026#34;u1\u0026#34;, harmonic) plot!(tr, \u0026#34;v1\u0026#34;, harmonic) p2 = plot(tr, [\u0026#34;u1\u0026#34;,\u0026#34;v1\u0026#34;], harmonic, legend=false, framestyle=:origin, aspect_ratio=1, lims=:symmetric) plot!([x0[1]],[x0[2]], markers=:true, line=false) plot!([tr.u[end][1]],[tr.u[end][2]], markers=:true, line=false) plot(p1, p2, size = plot_size, margin = margin) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e Although, at first sight looking at the response nothing changed much but when again performing frequency sweeps it becomes interesting.\nvaried = ω =\u0026gt; range(0.75, 1.25, 500) listβ = pairs([1.0, 0.5, 0.0, -0.5, -1.0]) results = Vector(undef, length(listβ)) plot1 = plot(;legend = false) for (i,beta) in listβ fixed = Dict(ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; 0.01, α =\u0026gt; beta, λ =\u0026gt; 1e-8, η =\u0026gt; 1e-8, θ =\u0026gt; 1e-8, ψ =\u0026gt; 1e-8) results[i] = get_steady_states(harmonic, varied, fixed; HB_settings...) plot!(results[i], x=\u0026#34;ω\u0026#34;, y=\u0026#34;sqrt(u1^2 + v1^2)\u0026#34;, color = beta == 0.0 ? :black : i+1, legend=false) end displ = -1:0.01:1 plot2 = plot(legend= :outerright, ylabel = \u0026#34;Potential energy\u0026#34;, xlabel = \u0026#34;x\u0026#34;) for (i,beta) in listβ pot = fixed[ω₀] .* displ.^2 + beta .* displ.^4 plot!(displ, pot, color = beta == 0.0 ? :black : i+1, label = \u0026#34;α = $beta\u0026#34;) end l = @layout [a{0.45w} b] plot(plot1, plot2, layout = l, legendfontsize=10, size = plot_size, margin = margin) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e Depending on $\\alpha$ the resonance frequency of the oscillator shifts. The larger the discrepancy of the driving frequency compared to the natural frequency (detuning), the larger the amplitude. Until it drops for really large detuning. The behaviour w.r.t. is asymmetric around the origin. For negative $\\alpha$, we observe instability for high displacements. We have a bifurcation when changing $\\alpha$ or $\\omega$, where we go from one state (stable) to three state (two stable, one unstable). Where the initial condition decides in which branch we will end up. Instability for $x_0\\approx \\omega_0^2/\\alpha_3$ Let us go to the complete time response picture again.\nx0 = [x =\u0026gt; 1.0, Dₜ(x) =\u0026gt; 0.0]; tspan = (0.0, 1000.0) p = [ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; 0.01, ω =\u0026gt; 1.0, α =\u0026gt; -0.99] prob = ODEProblem(sys, x0, tspan, p) tr = solve(prob, Tsit5(), saveat=0.1); plot1 = plot(tr.t, tr[1,:], xlabel=\u0026#34;t\u0026#34;, ylabel=\u0026#34;x(t)\u0026#34;, legend=false) plot2 = plot(tr, idxs=(1,2), xlab=\u0026#34;x(t)\u0026#34;, ylab=\u0026#34;v(t)\u0026#34;, legend=false, frame=:origin, lims=:symmetric) plot(plot1, plot2, size = plot_size, margin = margin) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e #| fig-align: center x0 = [x =\u0026gt; 1.0, Dₜ(x) =\u0026gt; 0.0]; tspan = (0.0, 2.0) p = [ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; 0.01, ω =\u0026gt; 1.0, α =\u0026gt; -1.0] prob = ODEProblem(sys, x0, tspan, p) tr = solve(prob, Tsit5(), saveat=0.1); plot1 = plot(tr.t , tr[1,:], xlabel=\u0026#34;t\u0026#34;, ylabel=\u0026#34;x(t)\u0026#34;, legend=false) displ = -1:0.01:1 plot2 = plot(legend= :outerright, ylabel = \u0026#34;Potential energy\u0026#34;, xlabel = \u0026#34;x\u0026#34;) for (i,beta) in listβ pot = fixed[ω₀] .* displ.^2 + beta .* displ.^4 plot!(displ, pot, color = beta == 0.0 ? :black : i+1, label = \u0026#34;α = $beta\u0026#34;) end plot(plot1, plot2, layout = l, legendfontsize=10, size = plot_size, margin = margin) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e The system becomes unstable for $x_0\\approx \\omega_0^2/\\alpha_3$. In general, we need that $x_0\\ll \\omega_0^2/\\alpha_3$\nHysteresis varied = ω =\u0026gt; range(0.9, 1.4, 150) fixed = Dict(ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; 0.01, α =\u0026gt; 1.0, λ =\u0026gt; 0.0, η =\u0026gt; 0.0, θ =\u0026gt; 0.0, ψ =\u0026gt; 0.0) result = get_steady_states(harmonic, varied, fixed; random_warmup=true, HB_settings...) plot(result, \u0026#34;sqrt(u1^2+v1^2)\u0026#34;) # linearly interpolate between two values at two times right_sweep = ParameterSweep(ω =\u0026gt; (0.9, 1.4), (0.0, 2e4)) ode_problem_right = ODEProblem(harmonic, fixed, sweep=right_sweep, x0=[0.01;0.0], timespan=(0.0,2e4)) left_sweep = ParameterSweep(ω =\u0026gt; (1.4, 0.9), (0.0, 2e4)) ode_problem_left = ODEProblem(harmonic, fixed, sweep=left_sweep, x0=[0.01;0.0], timespan=(0.0,2e4)) sol_right = solve(ode_problem_right, Tsit5(), saveat = 100); amplitude_right = sqrt.(sol_right[1,:].^2 + sol_right[2,:].^2) sol_left = solve(ode_problem_left, Tsit5(), saveat = 100); amplitude_left = sqrt.(sol_left[1,:].^2 + sol_left[2,:].^2) plot!(right_sweep[ω].(sol_right.t), amplitude_right, style=:dash, label=\u0026#34;left to right sweep\u0026#34;, linewidth=1) plot!(left_sweep[ω].(sol_left.t), amplitude_left, style=:dash, label=\u0026#34;right to left sweep\u0026#34;, linewidth=1) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e We observe hysteresis, i.e., the system takes different paths from high to low driving frequncy or visa versa.\nParamatric modulation Let us for a second assume nor driving or damping. We do introduce the periodic modulation of the natural frequency $\\omega_0$ such that are e.o.m. becomes:\n$$\\ddot{x}(t)+\\omega_0^2(1-\\lambda\\cos(2\\omega t + \\psi))x =0.$$\n@variables t x(t) # symbolic variables @parameters λ, ψ Dₜ = Differential(t) eq = Dₜ(Dₜ(x)) ~ - ω₀^2*(1-λ*cos(2*ω*t + ψ))*x - γ*Dₜ(x) + F*cos(ω*t) @named sys = ODESystem([eq], t, [x], [ω₀, ω, F, γ, α, λ, ψ]) sys = ode_order_lowering(sys) $$ \\begin{align} \\frac{\\mathrm{d} xˍt\\left( t \\right)}{\\mathrm{d}t} =\u0026amp; F \\cos\\left( t \\omega \\right) - \\gamma xˍt\\left( t \\right) - \\omega_0^{2} \\left( 1 - \\lambda \\cos\\left( \\psi + 2 t \\omega \\right) \\right) x\\left( t \\right) \\ \\frac{\\mathrm{d} x\\left( t \\right)}{\\mathrm{d}t} =\u0026amp; xˍt\\left( t \\right) \\end{align} $$\nIn the potential picture this effect changes the steepness of the harmonic potential periodically.\nInstability of the linear parametrically driven harmonic oscillator x0 = [x =\u0026gt; 1.0, Dₜ(x) =\u0026gt; 0.0]; tspan = (0.0, 1000.0) fixed = [ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; 0.0, ω =\u0026gt; 1.0, α =\u0026gt; 0.0, λ =\u0026gt; 0.1, ψ =\u0026gt; 0.0] prob = ODEProblem(sys, x0, tspan, fixed) tr = solve(prob, Tsit5(), saveat=0.1); plot1 = plot(tr.t , tr[1,:], xlabel=\u0026#34;t\u0026#34;, ylabel=\u0026#34;x(t)\u0026#34;, legend=false) plot2 = plot(tr, idxs=(1,2), xlabel=\u0026#34;x(t)\u0026#34;, ylabel=\u0026#34;v(t)\u0026#34;, legend=false, framestyle = :origin, lims = :symmetric) plot(plot1, plot2, size = plot_size, margin = margin) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e For different detuning\u0026rsquo;s $|\\omega-\\omega_0|$, we observe that the system becomes unstable or stable, where in the stable regions the steady states has always a zero amplitude. This corresponds with our intuition of the potential picture. Indeed, think about it.\nNotice how there is a resonance not at one value for $\\omega_p$, but for an infinite values of $\\omega_p$, i.e. in multiples of $\\omega$. This is in stark contract to normal external driving.\nWe cal the instability lobes Arnold tongues:\nThey appear at $2\\omega_0/\\omega_p=n$ with $n\\in \\mathbb{N}$ They broaden for increasing $\\lambda$ Linear dissipation $\\gamma$ can only stabilize the system for small $\\lambda$ The parametric instability threshold $\\lambda_{\\text {th }}=2 \\sqrt{(\\Omega \\bar{\\gamma})^2+\\left(1-\\Omega^2\\right)^2}$ with $\\Omega = \\omega/\\omega_0$, is where the system becomes unstable in the first instability lobe.\nParametric damping and amplification Again thinking in the potential picture, the phase $\\psi$ of the parametric drive becomes quiet important.\nx0 = [x =\u0026gt; 1.0, Dₜ(x) =\u0026gt; 0.0]; tspan = (0.0, 10.0) Q = 100 omega0 = 100 λₜₕ = 2/Q fixed = [ω₀ =\u0026gt; omega0, γ =\u0026gt; ω₀/Q, F =\u0026gt; 0.0, ω =\u0026gt; omega0, α =\u0026gt; 0.0, λ =\u0026gt; 0.9*λₜₕ, ψ =\u0026gt; -π/2] prob = ODEProblem(sys, x0, tspan, fixed) tr = solve(prob, Tsit5(), saveat=0.001); plot1 = plot(tr.t , tr[1,:], xlabel=\u0026#34;t\u0026#34;, ylabel=\u0026#34;x(t)\u0026#34;, legend=false) plot2 = plot(tr, idxs=(1,2), xlabel=\u0026#34;x(t)\u0026#34;, ylabel=\u0026#34;v(t)\u0026#34;, legend=false, framestyle = :origin, lims = :symmetric) plot(plot1, plot2, size = plot_size, margin = margin) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e x0 = [1.0, 0.0]; tspan = (0.0, 10.0); Q = 100; ω0 = 100; λₜₕ = 2/Q p1 = plot() for (lambda, psi) = [(0.0*λₜₕ, 0.0), (0.9*λₜₕ, -π/2), (0.9*λₜₕ, π/2)] fixed = (ω =\u0026gt; ω0, ω₀ =\u0026gt; ω0, γ =\u0026gt; ω0/Q, F =\u0026gt; 0.00, α =\u0026gt; 0.0, λ =\u0026gt; lambda, η =\u0026gt; 0.0, θ =\u0026gt; 0.0, ψ =\u0026gt; psi) ode_problem = ODEProblem(harmonic, fixed, x0 = x0, timespan = tspan) tr = solve(ode_problem, Tsit5(), saveat=0.1); plot!(tr, \u0026#34;u1\u0026#34;, harmonic) end varied = ω =\u0026gt; range(95, 105, 500) p2 = plot(;legend = false) for (i, (lambda, psi)) = pairs([(0.0*λₜₕ, 0.0), (0.9*λₜₕ, -π/2), (0.9*λₜₕ, π/2)]) fixed = (ω₀ =\u0026gt; omega0, γ =\u0026gt; omega0/Q, F =\u0026gt; 80.00, α =\u0026gt; 0.0, λ =\u0026gt; lambda, η =\u0026gt; 0.0, θ =\u0026gt; 0.0, ψ =\u0026gt; psi) result = get_steady_states(harmonic, varied, fixed) label = \u0026#34;λ = $(round(lambda; digits=2)), ψ = $(round(psi; digits=2))\u0026#34; plot!(result, x=\u0026#34;ω\u0026#34;, y=\u0026#34;sqrt(u1^2 + v1^2)\u0026#34;, color=i, label=label, legend=:best) end l = @layout [a{0.45w} b] plot(p1, p2, layout = l, legendfontsize = 10, size = plot_size, margin = margin) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e Indeed, we can cool or amplify the resonant peak observed in the stable non-zero amplitude steady states created with only linear damping (small $\\lambda$).\nStable Parametron without driving We need the nonlinear terms to stabilize the system. This can be done with the duffing $\\alpha$ term, studied before, and the non-linear damping $\\eta$: $$ \\ddot{x}(t)+\\gamma\\dot{x}(t)+\\omega_0^2(1-\\lambda\\cos(2\\omega t + \\psi))x + \\alpha x^3 +\\eta x^2 \\dot{x}=0 $$ Note that, neither linear ($\\gamma$) nor nonlinear damping ($\\eta$) is needed to stabilize the system. However, we will include it for completeness. Actually, one might also say, that the instability (i.e. the state of infinitely large amplitude) is just shifted to infinitely large detuning (of course other things of approximations probably break down earlier).\nvaried1 = ω =\u0026gt; range(0.98, 1.02, 300) fixed1 = Dict(ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; 0.0, α =\u0026gt; 1.0, λ =\u0026gt; 0.03, η =\u0026gt; 0.0, θ =\u0026gt; 0.0, ψ =\u0026gt; 0.0) result1 = get_steady_states(harmonic, varied1, fixed1; kwargs...) plot1 = plot(result1, \u0026#34;sqrt(u1^2+v1^2)\u0026#34;, legend=:best) fixed2 = Dict(ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; 0.0, α =\u0026gt; 1.0, η =\u0026gt; 0.0, θ =\u0026gt; 0.0, ψ =\u0026gt; 0.0) varied2 = (ω =\u0026gt; range(0.98, 1.02, 50), λ =\u0026gt; range(1e-6, 0.06, 50)) result_2D = get_steady_states(harmonic, varied2, fixed2; random_warmup=false, HB_settings...); plot2 = plot_phase_diagram(result_2D, class=\u0026#34;stable\u0026#34;) hline!([fixed1[λ]], style = :dash, color = :red, legend = false) plot(plot1, plot2, size = plot_size, margin = margin) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e The presence of a nonlinear force $β_3$ leads to an effective detuning of the resonance frequency as a function of the amplitude. This detuning causes a decrease of the pumping efficiency and a saturation of the growth. We observe that for small detuning the zero amplitude stable state is unstable, hence, not observed in nature. Nevertheless, in the region, there are two non-zero stable steady states degenerate in amplitude. These states we call the phase states. When increasing the driving frequency $\\omega$ the phase states keep existing, however, the zero amplitude state becomes stable again.\nThe region where the zero amplitude steady states is unstable is bounded by $$\\omega_{\\pm}^2=\\omega_0^2\\left(1 \\pm \\sqrt{\\frac{\\lambda^2}{4}-\\frac{1}{Q^2}}\\right).$$ Note, that $\\alpha$ and $\\eta$ have no influence on the boundaries as x is small at A ($\\omega_-$) and B ($\\omega_+$).\nvaried = ω =\u0026gt; range(0.98, 1.02, 300) fixed = Dict(ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; 0.0, α =\u0026gt; 1.0, λ =\u0026gt; 0.03, η =\u0026gt; 0.0, θ =\u0026gt; 0.0, ψ =\u0026gt; 0.0) result = get_steady_states(harmonic, varied, fixed; random_warmup=true, HB_settings...) plot_sweep = plot(result, \u0026#34;sqrt(u1^2+v1^2)\u0026#34;) x0_1 = [0.3, 0.2]; x0_2 = [-0.3, -0.2]; tspan = (0.0, 2000.0) fixed_tr = Dict(ω =\u0026gt; 1.0, ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; 0.00, α =\u0026gt; 1.0, λ =\u0026gt; 0.03, η =\u0026gt; 0.0, θ =\u0026gt; 0.0, ψ =\u0026gt; 0.0) ode_problem1 = ODEProblem(harmonic, fixed_tr, x0 = x0_1, timespan = tspan) ode_problem2 = ODEProblem(harmonic, fixed_tr, x0 = x0_2, timespan = tspan) tr1 = solve(ode_problem1, Tsit5(), saveat=0.1); tr2 = solve(ode_problem2, Tsit5(), saveat=0.1); plot_tr = plot(;framestyle = :origin, aspect_ratio=1, legend=false, lims = :symmetric) plot!(tr1, [\u0026#34;u1\u0026#34;, \u0026#34;v1\u0026#34;], harmonic, color = 1) plot!([x0_1[1]],[x0_1[2]], markers=:true, line=false, color=:green) plot!([tr1.u[end][1]],[tr1.u[end][2]], markers=:true, line=false, color=:orange) plot!(tr2, [\u0026#34;u1\u0026#34;, \u0026#34;v1\u0026#34;], harmonic, color = 1) plot!([x0_2[1]],[x0_2[2]], markers=:true, line=false, color=:green) plot!([tr2.u[end][1]],[tr2.u[end][2]], markers=:true, line=false, color=:orange) vline!(plot_sweep, [fixed_tr[ω]], style = :dash, color = :red, legend = false) plot(plot_sweep, plot_tr, size = plot_size, margin = margin) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e Ending up in one of the two phase states purely depends on the initial condition (I.C.).\nNote that the period of the response is twice as large as the drive. This is called periodicity doubling (time translation symmetry breaking).\nvaried1 = ω =\u0026gt; range(0.98, 1.02, 300) fixed1 = Dict(ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; 0.0, α =\u0026gt; 1.0, λ =\u0026gt; 0.03, η =\u0026gt; 0.5, θ =\u0026gt; 0.0, ψ =\u0026gt; 0.0) result1 = get_steady_states(harmonic, varied1, fixed1; random_warmup=true, HB_settings...) plot1 = plot(result1, \u0026#34;sqrt(u1^2+v1^2)\u0026#34;) fixed2 = Dict(ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; 0.0, α =\u0026gt; 1.0, η =\u0026gt; 0.5, θ =\u0026gt; 0.0, ψ =\u0026gt; 0.0) varied2 = (ω =\u0026gt; range(0.98, 1.02, 50), λ =\u0026gt; range(1e-6, 0.06, 50)) result_2D = get_steady_states(harmonic, varied2, fixed2; random_warmup=true, HB_settings...); plot2 = plot_phase_diagram(result_2D, class=\u0026#34;stable\u0026#34;) hline!([fixed1[λ]], style = :dash, color = :red, legend = false) plot(plot1, plot2, size = plot_size, margin = margin) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e When adding nonlinear damping $\\eta$ the phase states disappear for a large detuning.\nvaried = ω =\u0026gt; range(0.98, 1.02, 300) fixed = Dict(ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; 0.0, α =\u0026gt; 1.0, λ =\u0026gt; 0.03, η =\u0026gt; 0.0, θ =\u0026gt; 0.0, ψ =\u0026gt; 0.0) result1 = get_steady_states(harmonic, varied, fixed; random_warmup=true, HB_settings...) varied = ω =\u0026gt; range(0.98, 1.02, 300) fixed = Dict(ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; 0.0, α =\u0026gt; 1.0, λ =\u0026gt; 0.03, η =\u0026gt; 0.5, θ =\u0026gt; 0.0, ψ =\u0026gt; 0.0) result2 = get_steady_states(harmonic, varied, fixed; random_warmup=true, HB_settings...) plot(result1, \u0026#34;sqrt(u1^2+v1^2)\u0026#34;) plot!(result2, \u0026#34;sqrt(u1^2+v1^2)\u0026#34;) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e Driven Symmetry breaking in a Paramatron $$\\ddot{x}(t)+\\gamma\\dot{x}(t)+\\omega_0^2(1-\\lambda\\cos(2\\omega t + \\psi))x + \\alpha x^3 +\\eta x^2 \\dot{x}=F\\cos(\\omega t + \\theta)$$\nfixed = (ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, λ =\u0026gt; 0.05, F =\u0026gt; 0.001, α =\u0026gt; 1.0, η =\u0026gt; 0.3, θ =\u0026gt; 0, ψ =\u0026gt; 0) varied = ω =\u0026gt; range(0.92, 1.08, 500) result = get_steady_states(harmonic, varied, fixed) p = plot(result, x=\u0026#34;ω\u0026#34;, y=\u0026#34;sqrt(u1^2 + v1^2)\u0026#34;) timespan = (0.0, 2e4) # linearly interpolate between two values at two times right_sweep = ParameterSweep(ω =\u0026gt; (0.92, 1.1), timespan) ode_problem_right = ODEProblem(harmonic, fixed, sweep=right_sweep, x0=[0.01;0.0], timespan=timespan) left_sweep = ParameterSweep(ω =\u0026gt; (1.1, 0.92), timespan) ode_problem_left = ODEProblem(harmonic, fixed, sweep=left_sweep, x0=[0.01;0.0], timespan=timespan) sol_right = solve(ode_problem_right, Tsit5(), saveat = 100); amplitude_right = sqrt.(sol_right[1,:].^2 + sol_right[2,:].^2) sol_left = solve(ode_problem_left, Tsit5(), saveat = 100); amplitude_left = sqrt.(sol_left[1,:].^2 + sol_left[2,:].^2) plot!(right_sweep[ω].(sol_right.t), amplitude_right, style=:dash, label=\u0026#34;left to right sweep\u0026#34;, linewidth=1) plot!(left_sweep[ω].(sol_left.t), amplitude_left, style=:dash, label=\u0026#34;right to left sweep\u0026#34;, linewidth=1) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e $\\textcolor{red}{\\text{Help:}}$ Why is does the sweep from right to left hop to the highest amplitude branch? In Oded\u0026rsquo;s book it is stated that it should hop to the lowest amplitude branch.\nWhen we drive the parametron with an extra external drive $F$ we can break the amplitude degeneracy of the phase states. This is called parametric symmetry breaking.\nSpaghetti plots varied_sweep = ω =\u0026gt; range(0.98, 1.02, 600) fixed_sweep1 = Dict(ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; 0.0, α =\u0026gt; 1.0, λ =\u0026gt; 0.03, η =\u0026gt; 0.5, θ =\u0026gt; 0.0, ψ =\u0026gt; 0.0) fixed_sweep2 = Dict(ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; 0.0001, α =\u0026gt; 1.0, λ =\u0026gt; 0.01, η =\u0026gt; 0.5, θ =\u0026gt; 0.0, ψ =\u0026gt; 0.0) fixed_sweep3 = Dict(ω₀ =\u0026gt; 1.0, γ =\u0026gt; 0.01, F =\u0026gt; 0.0001, α =\u0026gt; 1.0, λ =\u0026gt; 0.03, η =\u0026gt; 0.5, θ =\u0026gt; 0.0, ψ =\u0026gt; 0.0) fixed_sweep = [fixed_sweep1, fixed_sweep2, fixed_sweep3] result_sweep = broadcast( p -\u0026gt; get_steady_states(harmonic, varied_sweep, p; HB_settings...), fixed_sweep ) plots = broadcast( res -\u0026gt; plot(plot(res, x=\u0026#34;ω\u0026#34;, y=\u0026#34;sqrt(u1^2 + v1^2)\u0026#34;), plot_spaghetti(res, x=\u0026#34;u1\u0026#34;, y=\u0026#34;v1\u0026#34;, z=\u0026#34;ω\u0026#34;), title = savename(res.fixed_parameters, connector = \u0026#34; \u0026#34;, accesses = (F, λ)), legend=:best), result_sweep ) plot(plots..., size = (720, 1200), layout = (3,1)) \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e ","date":"November 2, 2022","hero":"/posts/parametron/preview.png","permalink":"https://oameye.github.io/posts/parametron/","summary":"We try to understand the Kerr Parametric Oscillator (KPO) by slowly adding complexity the harmonic oscillator.","tags":["Julia","Tutorial"],"title":"From harmonic oscillator to the parametron"},{"categories":null,"contents":"This tutorial demonstrates how to compute the energy of a bosonic gas in a harmonic trap using automatic differentiation.\nusing ForwardDiff: derivative using CairoMakie, ProgressMeter using BenchmarkTools using Pkg; Pkg.status() Status `/var/home/oameye/Documents/hugo-toha/content/posts/automatic_differentiation/Project.toml` [13f3f980] CairoMakie v0.15.3 [634d3b9d] DrWatson v2.18.0 [f6369f11] ForwardDiff v1.0.1 [98b081ad] Literate v2.20.1 [92933f4c] ProgressMeter v1.10.4 using InteractiveUtils InteractiveUtils.versioninfo() Julia Version 1.10.10 Commit 95f30e51f41 (2025-06-27 09:51 UTC) Build Info: Official https://julialang.org/ release Platform Info: OS: Linux (x86_64-linux-gnu) CPU: 12 × AMD Ryzen 5 5600X 6-Core Processor WORD_SIZE: 64 LIBM: libopenlibm LLVM: libLLVM-15.0.7 (ORCJIT, znver3) Threads: 10 default, 0 interactive, 5 GC (on 12 virtual cores) Environment: JULIA_EDITOR = code JULIA_VSCODE_REPL = 1 JULIA_NUM_THREADS = 10 In statistical mechanics, the partition function is a central quantity that encodes all thermodynamic information of a system. For a bosonic gas in a harmonic trap, we need to compute the energy by differentiating the logarithm of the partition function with respect to the inverse temperature $β$.\nThe energy of a quantum system is given by: $$ E = -\\frac{\\partial}{\\partial \\beta} \\ln Z(\\beta) $$ where $Z(β)$ is the partition function and $β = 1/(k_B T)$ is the inverse temperature.\nSingle-Particle Partition Function The single-particle partition function for a d-dimensional harmonic oscillator: $$ z(\\beta, d) = \\left(\\frac{e^{-\\beta/2}}{1-e^{-\\beta}}\\right)^d $$ This accounts for the zero-point energy $(1/2)ℏω$ and the geometric series from the discrete energy levels $n·ℏω$.\nfunction z(β, d) return (exp(-0.5*β)/(1-exp(-β)))^d end; Many-Body Partition Function For N indistinguishable bosons, the partition function is computed recursively. This accounts for the bosonic statistics where multiple particles can occupy the same quantum state. The recursive formula is: $$ Z(N, \\beta, d) = \\frac{1}{N} \\sum_{k=1}^{N} z(k\\beta, d) \\cdot Z(N-k, \\beta, d) $$ with the boundary condition $Z(0, β, d) = 1$.\nThis recursion arises from the cluster expansion of the grand canonical partition function, accounting for all possible ways to distribute N particles among the available energy levels.\nfunction Z(N, β, d) if N == 0 return 1.0 else return (1 / N) * sum(z(k * β, d) * Z(N - k, β, d) for k in 1:N) end end; Energy Calculation via Automatic Differentiation The energy is computed as the negative logarithmic derivative of the partition function: $$ E = -\\frac{\\partial}{\\partial \\beta} \\ln Z(\\beta) $$\nWe implement two different approaches:\nBosonic: Uses the full many-body partition function Z(N, β, d) Boltzmann: Uses the classical approximation z(β, d)^N (non-interacting) The automatic differentiation (via ForwardDiff) computes the derivative analytically without numerical approximation, making it both accurate and efficient.\nfunction energy(N::Int64, β::Float64, d::Int64; type::Symbol = :boson) if type == :boson return -derivative(x -\u0026gt; log(Z(N, x, d)), β) else type == :boltzmannon return -derivative(x -\u0026gt; log(z(x, d)^N), β) end end; Numerical Experiment We now compute the energy for different numbers of particles N and different inverse temperatures β. This allows us to study:\nHow the energy depends on temperature $(β = 1/T)$ How quantum statistics affect the energy for different particle numbers The transition from quantum to classical behavior Parameter Space N: Number of particles $[1, 5, 10, 20]$ β: Inverse temperature range $[1, 10]$ (corresponds to $T ∈ [0.1, 1]$) d: Dimensionality = 1 (1D harmonic oscillator) range2d = Iterators.product([1, 5, 10, 20], 1:0.1:10) mat = @showprogress map(range2d) do (N, β) energy(N, β, 1) end 4×91 Matrix{Float64}: 1.08198 0.998961 0.931013 0.874631 0.827311 0.787217 0.75297 0.723516 0.698034 0.675874 0.656518 0.639545 0.62461 0.611431 0.599769 0.589425 0.580233 0.572048 0.564747 0.558227 0.552396 0.547174 0.542494 0.538296 0.534525 0.531138 0.528091 0.52535 0.522883 0.52066 0.518657 0.516852 0.515224 0.513755 0.51243 0.511234 0.510154 0.509179 0.508298 0.507502 0.506784 0.506134 0.505547 0.505017 0.504537 0.504104 0.503712 0.503357 0.503037 0.502747 0.502485 0.502248 0.502034 0.50184 0.501664 0.501506 0.501362 0.501232 0.501115 0.501009 0.500913 0.500826 0.500747 0.500676 0.500612 0.500553 0.500501 0.500453 0.50041 0.500371 0.500336 0.500304 0.500275 0.500249 0.500225 0.500204 0.500184 0.500167 0.500151 0.500136 0.500123 0.500112 0.500101 0.500091 0.500083 0.500075 0.500068 0.500061 0.500055 0.50005 0.500045 3.66075 3.43331 3.26044 3.12679 3.02189 2.93842 2.87119 2.81645 2.77143 2.73409 2.70286 2.67655 2.65424 2.63522 2.61891 2.60485 2.59269 2.58212 2.5729 2.56484 2.55776 2.55153 2.54604 2.54118 2.53687 2.53305 2.52965 2.52662 2.52392 2.52151 2.51935 2.51742 2.51568 2.51413 2.51274 2.51148 2.51036 2.50935 2.50844 2.50761 2.50688 2.50621 2.50561 2.50507 2.50458 2.50414 2.50374 2.50338 2.50306 2.50276 2.5025 2.50226 2.50204 2.50185 2.50167 2.50151 2.50137 2.50124 2.50112 2.50101 2.50091 2.50083 2.50075 2.50068 2.50061 2.50055 2.5005 2.50045 2.50041 2.50037 2.50034 2.5003 2.50027 2.50025 2.50023 2.5002 2.50018 2.50017 2.50015 2.50014 2.50012 2.50011 2.5001 2.50009 2.50008 2.50007 2.50007 2.50006 2.50006 2.50005 2.50005 6.18629 5.94648 5.76729 5.63038 5.52377 5.43941 5.37172 5.31673 5.27158 5.23417 5.2029 5.17657 5.15426 5.13523 5.11891 5.10486 5.09269 5.08212 5.0729 5.06484 5.05776 5.05153 5.04604 5.04118 5.03687 5.03305 5.02965 5.02662 5.02392 5.02151 5.01935 5.01742 5.01568 5.01413 5.01274 5.01148 5.01036 5.00935 5.00844 5.00761 5.00688 5.00621 5.00561 5.00507 5.00458 5.00414 5.00374 5.00338 5.00306 5.00276 5.0025 5.00226 5.00204 5.00185 5.00167 5.00151 5.00137 5.00124 5.00112 5.00101 5.00091 5.00083 5.00075 5.00068 5.00061 5.00055 5.0005 5.00045 5.00041 5.00037 5.00034 5.0003 5.00027 5.00025 5.00023 5.0002 5.00018 5.00017 5.00015 5.00014 5.00012 5.00011 5.0001 5.00009 5.00008 5.00007 5.00007 5.00006 5.00006 5.00005 5.00005 11.1866 10.9466 10.7673 10.6304 10.5238 10.4394 10.3717 10.3167 10.2716 10.2342 10.2029 10.1766 10.1543 10.1352 10.1189 10.1049 10.0927 10.0821 10.0729 10.0648 10.0578 10.0515 10.046 10.0412 10.0369 10.033 10.0296 10.0266 10.0239 10.0215 10.0193 10.0174 10.0157 10.0141 10.0127 10.0115 10.0104 10.0093 10.0084 10.0076 10.0069 10.0062 10.0056 10.0051 10.0046 10.0041 10.0037 10.0034 10.0031 10.0028 10.0025 10.0023 10.002 10.0018 10.0017 10.0015 10.0014 10.0012 10.0011 10.001 10.0009 10.0008 10.0007 10.0007 10.0006 10.0006 10.0005 10.0005 10.0004 10.0004 10.0003 10.0003 10.0003 10.0002 10.0002 10.0002 10.0002 10.0002 10.0002 10.0001 10.0001 10.0001 10.0001 10.0001 10.0001 10.0001 10.0001 10.0001 10.0001 10.0001 10.0 We plot the energy as a function of inverse temperature β for different particle numbers N. The log-log scale reveals the power-law behavior in different temperature regimes:\nHigh temperature (small β): Classical behavior E ∝ T Low temperature (large β): Quantum behavior dominated by zero-point energy Each curve represents a different particle number, showing how bosonic statistics modify the energy compared to the classical case.\nfig = Figure(size = (400, 250), fontsize = 7) ax = Axis(fig[1, 1], xscale = log10, yscale = log10, xlabel = \u0026#34;Inverse Temperature β\u0026#34;, ylabel = \u0026#34;Energy E\u0026#34;, title = \u0026#34;Energy of Bosonic Gas in Harmonic Trap\u0026#34;) for (i, N) in enumerate([1, 5, 10, 20]) row = mat[i, :] lines!(ax, 1:0.1:10, row, label = \u0026#34;N = $N\u0026#34;) end Legend(fig[1,2], ax) fig The results show several important features:\nZero-point energy: Even at $T → 0 (β → ∞)$, the energy remains finite due to quantum fluctuations Bosonic enhancement: Higher particle numbers show deviations from classical behavior due to quantum statistics Temperature scaling: The energy follows different power laws in different temperature regimes Version Information using InteractiveUtils InteractiveUtils.versioninfo() using Pkg Pkg.status() This page was generated using Literate.jl.\n","date":"April 2, 2022","hero":"/posts/automatic_differentiation/preview.png","permalink":"https://oameye.github.io/posts/automatic_differentiation/","summary":"Computing the energy of a bosonic gas in an harmonic trap using automatic differentiation.","tags":["Julia","Tutorial","Automatic Differentiation"],"title":"Automatic differentiation of a recursive partition function"},{"categories":null,"contents":"The text and method is based on the following sources:\nYoutube, 2D Schrodinger Equation Numerical Solution in PYTHON, (2022), Available at: (Accessed: 6 March 2022). Alexvas, Discretization of Laplacian with boundary conditions, (2017), Available at: (Accessed: 6 March 2022). Thomas H. Pulliam, David W. Zingg., Fundamental Algorithms in Computational Fluid Dynamics, (2014), Springer. using PyPlot, PyCall using LinearAlgebra using SparseArrays using Arpack, KrylovKit Two-dimensional box The goal is to solve the single particle Schrödinger equation in a two-dimensional box of length $2L$ of the Hamiltonian: $$ \\hat{h}=\\frac{-\\hbar^{2}}{2 m} \\nabla^{2}+V(\\mathbf{r}, t). $$ The box can have a homogeneous Dirichlet boundary condition, i.e., the wave function evaluated at the border must vanish, or periodic boundary conditions. There can be a potential $V$ in the box. So let us a meshgrid of $\\mathbf{x}$ and $\\mathbf{y}$ coordinates.\nN = 100 L = 10.0 Δx² = (2*L/N)^2 function meshgrid(x, y) X = [x for _ in y, x in x] Y = [y for y in y, _ in x] X, Y end x = LinRange(-L, L, N) y = LinRange(-L, L, N) X, Y = meshgrid(x, y); Potential The potential is chosen to be eightfold rotation symmetric quasicrystal, centered on $\\mathbf{r}=0,$ $$ V(\\mathbf{r})=V_{0} \\sum_{k=1}^{4} \\cos ^{2} \\left(\\mathbf{G}^k \\cdot \\mathbf{r}\\right), $$ where $V_{0}$ is the potential amplitude and the quantities $G^{k}$ are the lattice vectors of four mutually incoherent standing waves oriented at the angles $0^{\\circ}, 45^{\\circ}, 90^{\\circ}$, and $135^{\\circ}$, respectively. The lattice vectors have norm $\\left|G^{k}\\right|=\\pi / a$.\nfunction get_potential(x, y, V₀) return V₀*(cos(pi*x)^2 + cos(pi*√2/2*(x+y))^2 + cos(pi*y)^2 + cos(-pi/(√2)*(x-y))^2) end V = get_potential.(X,Y, 0.005) fig = figure(figsize=(6.2,5)) contourf(X, Y, V, 50) colorbar() Units The Schrödinger equation is given by $$ \\left[\\frac{-\\hbar^{2}}{2 m} \\nabla^{2}+V(\\mathbf{r})\\right] \\psi(\\mathbf{r}) = E\\psi(\\mathbf{r}),$$ Let us use the lattice spacing $a$ and the corresponding recoil energy $E_r = \\pi^2\\hbar^2/2ma^2$ as the space and energy units, respectively, such that we have\n$$ \\left[\\frac{-\\hbar^2}{2 m E_ra^2} \\tilde{\\nabla}^{2}+\\frac{V(\\mathbf{\\tilde{r}})}{E_r}\\right] \\psi(\\mathbf{\\tilde{r}}) = \\left[ \\frac{-1}{\\pi^2} \\tilde{\\nabla}^{2}+\\tilde{V}_{0} \\sum^4_k \\cos^{2}\\left(\\tilde{\\mathbf{G}}^{k} \\cdot \\tilde{\\mathbf{r}}\\right) \\right] \\psi(\\mathbf{\\tilde{r}}) = \\tilde{E}\\psi(\\mathbf{\\tilde{r}}), $$\nwhere $|\\tilde{\\mathbf{G}}_{k}|=\\pi$, $\\tilde{\\mathbf{r}} = \\frac{\\mathbf{r}}{a}$, and $\\tilde{E}=\\frac{E}{E_r}$.\nDiscretize in one dimension Rest us to discretize our Hamiltonian. The idea can be easily explained by the following finite difference approximation of the second derivative in one dimension $$ \\frac{d^2 \\psi}{dx^2} \\approx \\frac{\\psi_{i+1}-2\\psi_i + \\psi_{i-1}}{\\Delta x^2}.$$\nDirichlet boundary conditions Suppose we have $M=4$ interior points and $a$ and $b$ two boundary points, a mesh with four interior points $\\Delta x=2L /(M+1)$, represented as follows $$ \\begin{aligned} \u0026amp;\\qquad \\ \\ \\ \\ a \\ \\ \\ 1 \\ \\ \\ 2 \\ \\ \\ 3 \\ \\ \\ 4 \\ \\ \\ b \\\\\\ \u0026amp;x=- \\ L \\ - \\ - \\ - \\ - \\ \\ L \\end{aligned} $$ We impose Dirichlet boundary conditions, $u(-L)=u_{a}, u(L)=u_{b}$ and use the centered finite difference approximation at every point in the mesh. We arrive at the four equations:\n$$ \\left(d_{x x} u\\right)_{1} =\\frac{1}{\\Delta x^{2}} (u_a - 2 u_1 + u_2) $$\n$$ \\left(d_{x x} u\\right)_{2} =\\frac{1}{\\Delta x^{2}} (u_1-2 u_2+u_3) $$\n$$ \\left(d_{x x} u\\right)_{2} =\\frac{1}{\\Delta x^{2}} (u_2-2 u_3+u_4) $$\n$$ \\left(d_{x x} u\\right)_{4} =\\frac{1}{\\Delta x^{2}}\\left(u_3-2 u_4+u_b\\right) $$\nIntroducing $$ \\begin{aligned} \\vec{u}=\\left( \\begin{array}{c} \\psi_{1} \\\\\\ \\psi_{2} \\\\\\ \\psi_{3} \\\\\\ \\psi_{4} \\end{array} \\right) \\quad (\\overrightarrow{b c})=\\frac{1}{\\Delta x^{2}} \\left( \\begin{array}{c} \\psi_{a} \\\\\\ 0 \\\\\\ 0 \\\\\\ \\psi_{b} \\end{array} \\right) \\quad A=\\frac{1}{\\Delta x^{2}} \\left( \\begin{array}{rrrr} -2 \u0026amp; 1 \u0026amp; \u0026amp; \\\\\\ 1 \u0026amp; -2 \u0026amp; 1 \u0026amp; \\\\\\ \u0026amp; 1 \u0026amp; -2 \u0026amp; 1 \\\\\\ \u0026amp; \u0026amp; 1 \u0026amp; -2 \\end{array} \\right) \\end{aligned} $$ we can rewrite in matrix form as $$ \\begin{aligned} \\frac{d^2 \\psi}{dx^2} =\\frac{1}{\\Delta x^{2}}D= A \\vec{\\psi}+(\\overrightarrow{b c}) \\end{aligned} $$\nPeriodic boundary conditions This subsection has to be tested and worked out. First try did not work.\nSuppose we have $M=8$ points on a linear periodic mesh, represented as follows $$ \\begin{aligned} \u0026amp;\\cdots \\ \\ \\ 7 \\ \\ \\ \\ 8 \\ \\ \\ \\ \\ \\ a \\ \\ \\ \\ 1 \\ \\ \\ \\ 2 \\ \\ \\ \\ 3 \\ \\ \\ \\ 4 \\ \\ \\ \\ b \\ \\ \\ \\ 1 \\ \\ \\ \\ 2 \\ \\ \\ \\cdots \\\\\\ \u0026amp;x= \\ - \\ \\ - \\ \\ -L \\ \\ - \\ \\ - \\ \\ - \\ \\ - \\ \\ L \\ \\ - \\ \\ - \\end{aligned} $$ where we have that $\\psi(L)=\\psi(-L)$. It can be shown that the matrix representation is modified by $$ \\begin{aligned} \\frac{d^2 \\psi}{dx^2} =\\frac{1}{\\Delta x^{2}}D_p=\\frac{1}{\\Delta x^{2}} \\left( \\begin{array}{rrrr} -2 \u0026amp; 1 \u0026amp; \u0026amp; 1 \\\\\\ 1 \u0026amp; -2 \u0026amp; 1 \u0026amp; \\\\\\ \u0026amp; 1 \u0026amp; -2 \u0026amp; 1 \\\\\\ 1 \u0026amp; \u0026amp; 1 \u0026amp; -2 \\end{array} \\right) \\end{aligned} $$\nDiscretize in two dimensions In two dimensions, the wavefunction is not a vector anymore but a matrix. However, we would like to write it back as vector via the transformation $$ \\left( \\begin{array}{rrrr} \\psi_{11} \u0026amp; \\psi_{12} \u0026amp; \\cdots \u0026amp; \\psi_{1N} \\\\\\ \\psi_{21} \u0026amp; \\psi_{22} \u0026amp; \\cdots \u0026amp; \\psi_{2N} \\\\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\\\ \\psi_{N1} \u0026amp; \\psi_{N2} \u0026amp; \\cdots \u0026amp; \\psi_{NN} \\end{array} \\right) \\rightarrow \\left( \\begin{array}{c} \\psi_{11} \\\\\\ \\psi_{12} \\\\\\ \\vdots \\\\\\ \\psi_{NN} \\end{array} \\right) $$ The second derivative finite difference matrix must than be written as $$ \\frac{\\partial^2 \\psi}{\\partial x^2} = \\frac{1}{\\Delta x^{2}} I \\otimes D = \\frac{1}{\\Delta x^{2}} \\left( \\begin{array}{rrr} D \u0026amp; \u0026amp; \\\\\\ \u0026amp; \\ddots \u0026amp; \\\\\\ \u0026amp; \u0026amp; D\\end{array} \\right) $$ where $\\otimes$ is the Kronecker product. The 2D Laplacian can than be written as $$ \\nabla^{2} = \\frac{\\partial^2 \\psi}{\\partial x^2} + \\frac{\\partial^2 \\psi}{\\partial y^2} = \\frac{1}{\\Delta x^{2}} (I \\otimes D + D \\otimes I) = \\frac{1}{\\Delta x^{2}} D\\oplus D $$ where $\\oplus$ is the Kronecker sum, and we used that we discretized space as a squared grid, i.e. $\\Delta x^{2}=\\Delta y^{2}$.\nHamiltonian Let us assume the homogeneous Dirichlet Boundary conditions $\\psi(L, y) = \\psi(-L, y) = \\psi(x, L) = \\psi(x, -L) = 0$. The discretized Schrödinger equation can then be written as $$ \\left[-\\frac{1}{\\pi^2}(D \\oplus D) + \\Delta x^2 \\tilde{V} \\right] \\psi = \\left( \\Delta x^2 \\tilde{E}\\right) \\psi, $$ where $D$ has -2 on the main diagonal and 1 on the two neighboring diagonals and $\\psi$ is a vector. One could define the potential in units of $\\Delta x^2$; in other words get_potential actually returns $\\Delta x^2 V$. However, we will leave $\\Delta x^2$ in the kinetic term. Now we construct $$ \\hat{h} = -\\frac{1}{\\Delta x^{2}\\pi^2} D \\oplus D + \\tilde{V} $$ such that the corresponding eigenvalues $\\tilde{E}$ are in units of recoil energy $E_r$. Let $T=-\\frac{1}{\\Delta x^{2}\\pi^2} D \\oplus D$ and $U = V$\ndiag = ones(N); # vector of ones diags = Vector([diag[begin:end-1], -2*diag, diag[begin:end-1]]); # vector of vectors of the diagonals D = sparse(Tridiagonal(diags...)) # creates the discretised 2nd derivative T = -1/(Δx²*pi^2) * (kron(D, sparse(I,N,N)) + kron(sparse(I,N,N), D)) #N**2 x N**2 matrix U = spdiagm(reshape(V, N^2)) H = T+U; Here we used the package SparseArrays.jl to make the computations faster. Sparse arrays are arrays that contain enough zeros that storing them in a special data structure leads to savings in space and execution time, compared to dense arrays.\nEigenvectors and eigenvalues Now that we constructed our discretized Hamiltonian we can just exactly diagonalize our Hamiltonian to find the eigenvalues and eigenvector. We shall to this with the package Arpack.jl which is a Julia wrapper to a FORTRAN 77 library designed to compute a few eigenvalues and corresponding eigenvectors of large sparse or structured matrices, using the Implicitly Restarted Arnoldi Method (IRAM) or, in the case of symmetric matrices, the corresponding variant of the Lanczos algorithm. Both are classified as Krylov subspace based algorithms (see wikipedia). It is used by many popular numerical computing environments such as SciPy, Mathematica, GNU Octave and MATLAB to provide this functionality.\nWe use the eigs function where nev specifies how many eigenvalues and eigenvectors we want and which specifies the type of eigenvalues to compute. For my purposes I only need the ground state wave function.\nAlternatively, one could use KrylovKit.jl, a native Julia package collecting a number of Krylov-based algorithms for linear problems, singular value and eigenvalue problems and the application of functions of linear maps or operators to vectors. With KrylovKit.jl I manage to find better results if when I increase the number of point $N$. My theory is that it, as black box solver, uses another method above a certain threshold $N^*$, whereas Arpack.jl sticks to the same method and hence gives worse results.\n# eigenvalues, eigenvectors = eigs(H, nev=1, which=:SM); _, vecs, _ = eigsolve(H, 1, :SR); # vecs[1] As we constructed the Hamiltonian to be a $N^2 \\times N^2$ so that $\\psi$ could be a vector, we have to reshape the eigenvectors back to a $N \\times N$ matrix.\nfunction get_e(n::Int64) return reshape(vecs[1]\u0026#39;, N, N) end; figure(figsize=(6.2,5)) pcolormesh(X, Y, get_e(0)^2, cmap=:RdBu) colorbar() # contourf(X, Y, get_e(0)^2, 100) Summary using PyPlot, PyCall using LinearAlgebra using SparseArrays using Arpack, KrylovKit function meshgrid(x::LinRange{Float64, Int64}, y::LinRange{Float64, Int64})::Tuple{Matrix{Float64}, Matrix{Float64}} X = [x for _ in y, x in x] Y = [y for y in y, _ in x] X, Y end function QC(x::Float64, y::Float64, V₀::Float64)::Float64 return V₀*(cos(pi*x)^2 + cos(pi*√2/2*(x+y))^2 + cos(pi*y)^2 + cos(-pi/(√2)*(x-y))^2) end function free(x::Float64, y::Float64, V₀::Float64)::Float64 return V₀*(0*x+0*y) end function PC(x::Float64, y::Float64, V₀::Float64)::Float64 return V₀*(sin(pi*x)^2+sin(pi*y)^2) end function eigenfunctionDBCArpack(V::Matrix{Float64}, L::Float64, N::Int64) Δx² = (2*L/N)^2 # creates the discretised 2nd derivative D = sparse(Tridiagonal(ones(N-1), -2*ones(N), ones(N-1))) # N**2 x N**2 matrix T = -1/(Δx²*pi^2) * (kron(D, sparse(I,N,N)) + kron(sparse(I,N,N), D)) U = spdiagm(reshape(V, N^2)) H = T + U; _, eigenvector = eigs(H, nev=1, which=:SM); return reshape(eigenvector\u0026#39;, N, N) end function eigenfunctionDBCKrylov(V::Matrix{Float64}, L::Float64, N::Int64) Δx² = (2*L/N)^2 # creates the discretised 2nd derivative D = sparse(Tridiagonal(ones(N-1), -2*ones(N), ones(N-1))) # N**2 x N**2 matrix T = -1/(Δx²*pi^2) * (kron(D, sparse(I,N,N)) + kron(sparse(I,N,N), D)) U = spdiagm(reshape(V, N^2)) H = T + U; _, vecs, _ = eigsolve(H, 1,:SR) # _, eigenvector = eigs(H, nev=1, which=:SM); return reshape(vecs[1]\u0026#39;, N, N) end # function eigenfunctionPBC(V::Matrix{Float64}) # Δx² = (2*L/N)^2 # # creates the discretised 2nd derivative # D = sparse(Tridiagonal(ones(N-1), -2*ones(N), ones(N-1))) # D[1, end] = 1.0 # D[end, 1] = 1.0 # # N**2 x N**2 matrix # T = -1/(Δx²*pi^2) * (kron(D, sparse(I,N,N)) + kron(sparse(I,N,N), D)) # U = spdiagm(reshape(V, N^2)) # H = T + U; # N = size(V)[1] # # creates the discretised 2nd derivative # D = sparse(Tridiagonal(ones(N-1), -2*ones(N), ones(N-1))) # _, eigenvector = eigs(H, nev=1, which=:SM); # return reshape(eigenvector\u0026#39;, N, N) # end V₀ = 0.8 L = 50.0 Δx² = 0.1 N = Int64(div(2L, Δx²)) X, Y = meshgrid(LinRange(-L, L, N), LinRange(-L, L, N)); V = QC.(X, Y, V₀) ef = eigenfunctionDBCKrylov(V, L, N) fig, axes = subplots(nrows=1, ncols=2, figsize=(12, 5)) im1 = axes[1].pcolormesh(X[450:550,450:550], Y[450:550,450:550], V[450:550,450:550], cmap=:RdBu) colorbar(im1, ax=axes[1]) im2 = axes[2].pcolormesh(X[450:550,450:550], Y[450:550,450:550], ef[450:550,450:550]^2, cmap=:RdBu) colorbar(im2, ax=axes[2]) PyObject \u0026lt;matplotlib.colorbar.Colorbar object at 0x000000006E89FF40\u0026gt; # @pyimport matplotlib.animation as anim # using Base64 # fig = figure(figsize=(6.2,5)) # function make_frame(i) # V₀ = 0.02*i # L = 10.0 # N = 150 # X, Y = meshgrid(LinRange(-L, L, N), LinRange(-L, L, N)); # V = QC.(X, Y, V₀) # ef = eigenfunctionDBC(V) # pcolormesh(X, Y, ef^2, cmap=:RdBu) # end # withfig(fig) do # myanim = anim.FuncAnimation(fig, make_frame, frames=20, interval=200) # myanim[:save](\u0026#34;test2.mp4\u0026#34;, bitrate=-1, extra_args=[\u0026#34;-vcodec\u0026#34;, \u0026#34;libx264\u0026#34;, \u0026#34;-pix_fmt\u0026#34;, \u0026#34;yuv420p\u0026#34;]) # end # function showanim(filename) # base64_video = base64encode(open(filename)) # display(\u0026#34;text/html\u0026#34;, \u0026#34;\u0026#34;\u0026#34;\u0026lt;video controls src=\u0026#34;data:video/x-m4v;base64,$base64_video\u0026#34;\u0026gt;\u0026#34;\u0026#34;\u0026#34;) # end # showanim(\u0026#34;test2.mp4\u0026#34;) ","date":"March 28, 2022","hero":"/posts/eigenfunctions/featured.png","permalink":"https://oameye.github.io/posts/eigenfunctions/","summary":"The eigenfunctions of the time independent Schrödinger equation are numerically computed by discretising with the finite difference method and using exact diagonalisation of sparse matrices.","tags":["Julia","Tutorial"],"title":"Diagonalising 2D Schrödinger Equation"}]